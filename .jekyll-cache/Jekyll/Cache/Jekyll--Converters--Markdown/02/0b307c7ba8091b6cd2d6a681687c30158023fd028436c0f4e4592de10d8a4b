I"<p>의사 결정트리에 대해 알아볼껀데, 의사 결정트리가 어떤 상황에서 사용되는지 구현하려면 무엇이 필요한지에 대해 알아보겠습니다.</p>

<h2 id="의사-결정트리decision-tree">의사 결정트리(Decision Tree)</h2>

<p>회귀식을 세울 때 중요한 변수(컬럼)들을 선택해야 하는 상황에서 어떠한 컬럼이 중요한지 판단이 안설때, 의사 결정트리를 이용하면 중요한 변수를 골라낼 수 있습니다.</p>

<p>예를 들어 회사 지원자에게 떨어진 이유를 명확히 설명해줘야 하는 경우나 은행에서 대출을 해줄 때, 대출을 해줄지 말지의 여부를 기업 데이터를 보고 결정해야 하는 경우 등이 있습니다. 또 의학면에서는 질병에 대한 진행바탕으로 올바른 처방을 위해 결정해야하는 경우에 사용되기도 합니다.</p>

<p><img src="/public/img/tree.png" alt="tree" width="80%" height="80%" class="center" /></p>
<center>Decision Tree 예시</center>

<h2 id="엔트로피entropy와-정보획득량">엔트로피(entropy)와 정보획득량</h2>

<p>의사 결정트리를 이야기 하다가 왜 갑자기 엔트로피 이야기가 나올까요 ? <br />
결정트리를 만들 때, 가장 먼저 해야할 일은 <strong>중요한 변수(컬럼)</strong>을 찾는 것입니다. 즉, 정보획득량이 높은 변수를 찾아야하는데, 그때 엔트로피 함수를 사용합니다.</p>

<ul>
  <li>
    <p>엔트로피(entropy) 함수</p>

    <p>엔트로피는 <strong>“데이터의 불확실성이 얼마나 되는가?”</strong>를 알수 잇는 지표입니다. 즉, <strong>엔트로피 지수가 높다는 것은 불확실성이 높다</strong>는 것을 알 수 있습니다.</p>
  </li>
  <li>
    <p>엔트로피 그래프</p>
  </li>
</ul>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">curve</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">log2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">log2</span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x</span><span class="p">),</span><span class="n">col</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"x"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Entropy"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">4</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/public/img/entro.png" alt="entro" width="30%" height="30%" class="center" /></p>

<p>정보획득량은 분할전 엔트로피에서 분할 후 엔트로피를 빼면 정보획득량을 구할 수 있습니다.</p>
:ET