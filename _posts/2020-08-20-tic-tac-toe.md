---
title:  강화학습으로 tic tac toe 학습 시키기전 필요 요소
date:   2020-08-20 09:00:00 +0300
categories:  [Machine Learning, ML]
sitemap :
math: true
mermaid: true
changefreq : always
priority : 1.0
use_math: true
---

강화학습을 이용해서 tic tac toe을 만들어볼까한다. 
**강화**는 동물이 시행착오를 통해 학습하는 방법 중 하나로 강화라는 개념을 처음 제시한 스키너라는 행동 심리학자이다.  

강화라는 것은 동물이 이전에 배우지 않았지만 직접 시도하면서 행동과 그 결과를 나타나는 좋은 보상 사이에 상관관계를 학습하는 것이다.  

핵심은 바로 보상을 얻게해주는 행동의 빈도의 증가이다. 다른말로 애기하면 보상을 얻게 하는 행동을 점점 더 많이 하도록 학습하는 것을 말한다.

## 지도학습과 강화학습의 차이

강화학습으로 tic tac toe를 만들기 전에 우선 지도학습과 강화학습의 차이 정도는 알고 가자. 사실 위에서 TMI로 많이 이야기 했지만.. 어쨋든 한번은 짚고 넘어가야 댈듯하다.  

지도학습은 직접적인 정답을 통해 오차를 계산해서 학습하는 것이고, 강화학습은 자신의 행동의 결과로 나타나는 보상을 통해 학습하는 것을 이야기 한다.   
서로 다른 방식으로 학습을 하기 때문에 이 점은 꼭 기억하자.

## 강화학습에 필요한 요소

강화학습에 필요한 요소를 정리하려고 한다. TMI로 **순차적으로 행동을 계속 결정해야하는 문제를 수학적으로 표현한 것을 MDP( Markov Dicision Process )**라고 한다. 아무튼 강화학습에 필요한 요소는 다음과 같다.

1. 상태
2. 행동
3. 보상함수
4. 상태변환확률
5. 감가율

정말 필요한 기본 요소들만 적었기 때문에 다른 강화학습 모델을 만든다고 하면 저 필요 요소보다 더 필요할 것이다.  

틱텍토 코드의 중요한 특징 2가지가 있는데, 아래와 같다.

1. 각 수에 대한 가중치를 점점 갱신해 나간다.
2. 수를 둘 때마다 랜덤수를 던진다. (10번중 1번으로)

위의 1번의 경우 금방 납득을 할 수 있겠지만, 2번의 경우는 이해가 안될 수 있다.  
랜덤수를 던지는 이유는 랜덤 수가 없다면 학습된 데이터로만 계속 둘 것이다. 그렇다면 더 좋은 수가 있는데, 더 좋은 수를 발견 못하고 계속 같은 게임만 하게 될 수도 있다. 그렇기 때문에 중간중간 랜덤의 수를 던져야 한다. 

다음 포스팅 때는 필요 요소를 기반으로 기본 코드를 짜보겠다. 