---
title:  나이브 베이즈(Naive Bayes) 확률로 인한 데이터 분류(조건부확률과 베이즈 정리)
date:   2020-02-11 09:00:00 +0300
categories:  [Machine Learning, ML]
sitemap :
math: true
mermaid: true
changefreq : always
priority : 1.0
use_math: true
---

오늘부터 나이브 베이즈(Naïve Bayes)에 대해 알아보겠습니다. 나이브 베이즈는 확률을 기반으로 한 머신러닝의 한 알고리즘입니다. 현재까지도 유용하고 많이 사용되고 있어서 알아둬야합니다. 

## 확률로 인한 데이터 분류

기상학자가 날씨예보를 할 때, 일반적으로 "비올 확률 70%" 라는 용어를 사용해 예측을 합니다. 여기서 나온 70%는 과거의 사건 데이터를 사용한 것이며, 과거에 이런 경우가 10번 중 7번은 비가 왔음을 의미하는 것입니다. **베이즈기법 기반인 분류기는 분류되지 않은 데이터를 분류기가 분류할때, 새로운 속성에 대한 가장 유사한 범주를 예측하기 위해 관찰된 확률**을 사용합니다. 관찰된 확률은 훈련 데이터에서 의해서 미리 계산이 되어집니다. 

<center><img src="../../assets//images/NB1.png" ></center>

## 확률 이론

확률에는 결합 확률, 조건부 확률, 베이즈 정리가 있습니다. 

**1. 결합 확률**
결합 확률은 서로 배반되는 두 사상 E와 F가 있을 때, 두 사상이 연속적으로 또는 동시에 일어나는 확률을 결합 확률이라고 합니다. 

$$
P(E∩F)
$$

예를 들면 로또에 당첨될 확률과 벼락에 맞을 확률이 동시에 일어나는 것이 있습니다. 

**2.조건부 확률**
어떠한 상항이 주어졌을때, 그 상황속에서 다른 상황이 일어날 확률을 조건부 확률이라고 합니다.

$$
P(A|B)
$$

예를 들어 A를 우산이 팔릴 확률, B가 비가 올 확률이라고 할때, 비가 오면서 우산이 팔릴 확률을 들 수 있습니다.

**3.베이즈 정리**

베이즈 정리는 조건부 확률의 조건과 사건 자체를 바꿔서 생각할 수 있도록 해주는 방법입니다. 

$$
P(A∩B)*P(B)=P(B|A)*P(A) 
$$

## 사건 

사건이라는 개념이 존재하며 사건이란, 화창하거나 또는 비가 올 날씨, 동전 던지기에서 앞면 또는 뒷면이 나오는 경우들, 스팸 메일과 햄 메일이 같이 일어날 사건 등을 이야기 합니다. 


**1.독립 사건**
독립 사건은 두 사건이 동시에 일어났는데, 두 사건이 서로 전혀 연관되지 않았다면 그건 독립 사건입니다. 예를 들어 동전 던지기의 결과와 화창한 날씨는 서로 독립적입니다. 확률 이론을 적용하자면 아래와 같습니다.

$$
P(A∩B)=P(A)*P(B)\\
P(A|B)=P(A)\\ | 의미는 사건 B가 일어날 때 사건 A의 확률 \\ 
P(B|A)=P(B)\\
$$

**2.종속 사건**
종속 사건은 사건 A가 일어났을 경우와 일어나지 않았을 경우 따라서 사건 B가 일어날 확률이 다를 때 B는 A의 종속 사건이라고 합니다. 확률 이론을 적용하면 아래와 같습니다.

$$
P(A∩B)=P(A)*P(B|A)\\
P(A)*P(A|B)
$$

## 확률 예제

실제로 구해야 하는 공식이 

$$P( B | A )$$

이라고 할 때, "비아그라"라는 메시지가 메일에 포함되어져있을 때 스팸일 확률을 구하자면 아래와 같은 공식이 나올 수 있습니다. 

$$
P(B|A)=P(A∩B)/(A)\\
P(A|B)=P(A∩B)/(B)
$$

또한 스팸 메일일 확률이 20%이고, 햄인 메일인 확률이 80%이면 스팸이 아닐 확률을 표기하는 방법은 아래와 같이 구할 수 있습니다.

$$
스팸일 확률:P(스팸)=0.2\\
햄일 확률:p(햄)=0.8\\
p(~스팸):0.8
$$

위와 같이 구할 수 있습니다. 다음은 이를 토대로 나이브 베이즈 분류를 해보도록 하겠습니다.