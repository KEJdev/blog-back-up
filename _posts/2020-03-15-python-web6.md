---
layout: post
title:  네이버에서 이미지 크롤링하기
date: 2020-03-15 11:00:00 +0300
category : Python
use_math : true
---     

저번 포스팅에서는 신문사를 크롤링하는 것을 해봤는데, 이번에는 네이버에서 이미지를 크롤링하는 것을 해볼까합니다. 

## 이미지 크롤링

이미지 크롤링할 때 필요한 모듈은 아래와 같습니다. 

```python
import urllib.request
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.common.keys import Keys  
# 웹 애플리케이션의 테스트를 자동화하기 위한 프레임 워크
# 손으로 마우스 클릭해서 데이터를 검색하고 스크롤링 할 수 있다

import time
# 중간마다 sleep를 걸어야 한다.
```


그리고 저번 신문사 크롤링과는 다르게 이번에 chromedriver가 필요하기 때문에 다운해야합니다. [여기](https://chromedriver.chromium.org/downloads)에서 OS와 버전에 맞게 다운로드 해주세요. chromedriver는 크롬 웹 브라우저를 열기 위한 것이기 때문에 필요합니다. 

그리고 네이버 이미지에서 검색창 id를 확인해주세요.

![web12](/public/img/web12.png){: width="100%" height="100%" }{: .center}

id는 위 그림과 같이 nx_query임을 알 수 있으며, 이제 아래와 같이 코드를 구현할 수 있습니다. 


```python
binary = 'chromedriver.exe'
# 크롬 웹 브라우저를 열기 위한 크롬 드라이버
# 팬텀 js를 이용하면 백그라운드로 실행 할 수 있음.

browser = webdriver.Chrome(binary)
# 브라우저를 인스턴스화 

browser.get("https://search.naver.com/search.naver?where=image&amp;sm=stb_nmr&amp;")
# 네이버의 이미지 검색 url

elem = browser.find_element_by_id("nx_query")
# nx_query는 네이버 이미지 검색에 해당하는 input창 id
```

그리고 검색어를 입력과 웹에서 submit = enter의 역활을 하는 코드를 아래와 같이 작성합니다.

```python
elem.send_keys("아이언맨")
elem.submit()
```

이제 이미지 저장과 반복할 횟수 그리고 time sleep를 걸어놓습니다. time sleep을 거는 이유는 네트워크의 속도를 위해 5초의 sleep을 걸어놓습니다. 꼭 필요한 것은 아니지만 안정성이나 네트워크가 느려질 수 있으므로 걸어두는 것이 좋습니다. 

또한 이미지 크롤링 하면서 페이지를 내리기 위해 body를 활성화하여 페이지를 내리겠습니다. 

```python
# 스크롤링( 스크롤을 내리는 동작)을 반복할 횟수
for i in range(1, 2):
    browser.find_element_by_xpath("//body").send_keys(Keys.END)
    # 웹창을 클릭 후 END키를 누르는 동작
    # 브라우저 아무데서나 END키 누른다고 페이지가 내려가지 않음
    # body를 활성화한 후 스크롤 동작

    time.sleep(5)
    # 이미지가 로드 되는 시간 5초 
    # 로드가 되지 않은 상태에서 자장하기 되면 No image로 뜸.

time.sleep(5) 
# 네크워크의 속도를 위해 걸어둔 sleep
```

이제 이미지를 다운 받아 로컬에 저장 하겠습니다. 


```python
html = browser.page_source
# 크롬 브라우저에서 현재 불러온 소스 코드를 가져옴

soup = BeautifulSoup(html, "lxml")
# beautiful soup을 사용해서 html 코드를 검색할 수 있도록 설정

def fetch_list_url():
    # 이미지를 url이 있는 img 태그의 img클래스로 감
    params = []
    imgList = soup.find_all("img", class_="_img")
    for im in imgList:
        # params 리스트 변수에 images url을 담음
        params.append(im["src"])
    return params

def fetch_detail_url():
    params = fetch_list_url()
    a = 1
    for p in params:
        # 다운받을 폴더경로 입력
        urllib.request.urlretrieve(p,  str(a) + ".jpg")
        a = a + 1

fetch_detail_url()

# 브라우저 창 닫기
browser.quit()
```


