<!DOCTYPE html><html lang="en" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.1.1" /><meta property="og:title" content="논문 리뷰 - Image-to-Image Translation with Conditional Adversarial Networks" /><meta name="author" content="KEJdev" /><meta property="og:locale" content="en_US" /><meta name="description" content="Paper URL : https://arxiv.org/pdf/1611.07004.pdf" /><meta property="og:description" content="Paper URL : https://arxiv.org/pdf/1611.07004.pdf" /><link rel="canonical" href="https://kejdev.github.io/posts/pix2pix/" /><meta property="og:url" content="https://kejdev.github.io/posts/pix2pix/" /><meta property="og:site_name" content="🍗 양념치킨 🍗" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-02-15T15:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="논문 리뷰 - Image-to-Image Translation with Conditional Adversarial Networks" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"KEJdev"},"dateModified":"2022-08-02T23:27:54+08:00","datePublished":"2022-02-15T15:00:00+08:00","description":"Paper URL : https://arxiv.org/pdf/1611.07004.pdf","headline":"논문 리뷰 - Image-to-Image Translation with Conditional Adversarial Networks","mainEntityOfPage":{"@type":"WebPage","@id":"https://kejdev.github.io/posts/pix2pix/"},"url":"https://kejdev.github.io/posts/pix2pix/"}</script><title>논문 리뷰 - Image-to-Image Translation with Conditional Adversarial Networks | 🍗 양념치킨 🍗</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/favicon.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-148043528-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-148043528-1'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" style="width:190px" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div style="display:flex"><div id="avatar" style="margin:0 auto 0 auto;"> <a href="/" alt="avatar" class="mx-auto"> <img style="max-width:100%;" src="/assets/img/favicons/mycat.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div></div><div style="display:flex"><div style="margin:0 auto 0 auto; font-weight:550px;" > <a href="/">🍗 양념치킨 🍗</a></div></div><div style="display:flex"><div class="site-subtitle font-italic" style="margin:0 auto 0 auto;">고양이 좋아하는 개발자</div></div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <span>HOME</span> </a><li class="nav-item"> <a href="/tabs/categories/" class="nav-link"> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tabs/archives/" class="nav-link"> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/tabs/about/" class="nav-link"> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post-content" style="margin-top:70px;"><h1 data-toc-skip>논문 리뷰 - Image-to-Image Translation with Conditional Adversarial Networks</h1><div class="post-meta text-muted d-flex flex-column" style="border-bottom:1px solid black;" ><div > <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Tue, Feb 15, 2022, 3:00 PM +0800" > Feb 15 <i class="unloaded">2022-02-15T15:00:00+08:00</i> </span> by <span class="author"> KEJdev </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Wed, Aug 3, 2022, 12:27 AM +0900" > Aug 3 <i class="unloaded">2022-08-02T23:27:54+08:00</i> </span> </span></div></div><div class="post-content"><p>Paper URL : <a href="https://arxiv.org/pdf/1611.07004.pdf">https://arxiv.org/pdf/1611.07004.pdf</a></p><p>Pix2Pix논문에 대해 리뷰 해볼까한다. 2018년도에 나온 논문이고 상당히 유명한 모델이다. 이번 논문 리뷰에서는 GAN에 대한 기본 개념은 어느정도 있다고 생각하고 글을 썼으니, 혹시나 헷갈리는 부분이 있다면 다시 한번 보고 오기를 바란다.</p><h2 id="요약">요약</h2><ol><li>다양한 image-to-image translation task를 수행하는 general-purpose GAN을 제안했다.<ul><li>네트워크 구조나, 목적 함수에 변경 없이 다양한 이미지 변환 task를 수행할 수 있다.<li>저자들은 이를 ‘모델이 데이터에 적응하는 loss를 학습한다’ 라고 표현하고 있다.</ul><li>convolutional conditional GAN을 backbone으로 하였고, 목적함수에 L1 loss 추가하였다.<ul><li>구체적으로 generator는 U-Net구조, discriminator는 patchGAN을 사용하였다.</ul></ol><h2 id="introduction">Introduction</h2><p>이미지 변환에 대한 과거 연구들은 모두 task마다 별도로 세분화된 모델/기술을 사용하여 문제를 해결하였다.</p><center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/images/pix2pix_1.png" /></center><p>논문의 저자들은 <strong>이미지 변환이라는게 결국 from pixels to pixels 라는 하나의 공통된 세팅하에 수행된다는 사실에 주목</strong>하였다. 그래서 모든 이미지 변환 task들을 해결할 수 있는 common framework를 제안하는 것을 목적으로 연구했다.</p><p><strong>automatic image-to-image translation</strong> : 어떤 한 장면에 대한 representation을 다른 representation으로 바꾸어 표현하는 task.</p><h2 id="objective">Objective</h2><p>저자들은 이전 연구인 GAN의 main objective에서 L2 distance등의 전통적인 loss를 추가하는 것이 이로움을 확인하였다. (아래 그림 수식(1))</p><center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/images/pix2pix_2.png" /></center><p>특히 generator가 ground truth output에 pixel단위로 더 비슷해지게 만드는 효과가 있는데, L2보다 L1이 결과가 덜 blurring해서 저자들은 L1 distance를 사용했다고 한다.</p><center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/images/pix2pix_3.png" /></center><p>그 결과 생성 이미지의 결과가 완전 deterministic해졌다.(동일한 Input을 넣으면 항상 동일한 Output이 나옴). 저자들은 여기에 약간의 stochastic을 추가하기 위해 dropout을 train/test time 모두에 작동하도록 세팅하였다. 하지만 큰 랜덤성은 확보하지 못했다는 limitation이 남아있다.</p><h2 id="model">Model</h2><ul><li><p><strong>Generator</strong></p><p>저자들은 Encoder-decoder 네트워크를 토대로 level별로 처리된 feature들의 정보를 효율적으로 이용할 수 있도록 connection을 추가한 U-Net구조를 generator의 아키텍쳐로 사용하였다.</p><center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/images/pix2pix_4.png" /></center><li><p><strong>Discriminator</strong></p><p>L2와 L1 Loss는 계산될때, 모든 픽셀값들에 대해 averaging되기 때문에, image generation시 high-level 특성을 잘 살리지 못하고 blurry한 결과를 줄 수 있다. </p><p><strong>그러나</strong>, L2, L1 손실들은 low-level 특성은 정확하게 잘 포착해낼 수 있다</p><p>따라서 discriminator의 구조를 고려할 때, 저자들은 high-level structure를 잘 살려낼 수 있도록 하는 모델을 선택할 필요가 있었고, PatchGAN의 discriminator를 사용하게 되었다.</p><li><strong>Optimization &amp; inference</strong> <center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/images/pix2pix_5.png" /></center><p>최적화 시키기 위해 모델은 discriminator 한번, generator 한번 번갈아 학습하였고, \(log(1-D(x,G(x,z))\)를 최소화하는 대신 \(logD(x,G(x,z))\)를 최대화하는 방향으로 학습하였다. \(D\)를 최적화하는 동안 목적함수를 2로 나눠서 G와 비교한 상대적 학습률을 조금 늦췄으며, 파라미터는 Adam, lr=0.0002, beta1=0.5, beta2=0.999이다. 특이하게, inference시에도 train시와 동일하게 적용되도록 dropout이나 bn등이 train mode로 작동하게 하였다.</p><li><strong>Conclusion</strong> <center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/images/pix2pix_6-1.png" /></center><p>결과물만 확인해보면 질적인 실험결과는 cGAN이 세그멘테이션을 잘 수행함을 보여주고 있다.</p><center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/images/pix2pix_6.png" /></center><p>그러나 양적인 실험결과는 오히려 단순히 노말 GAN+L1 Loss를 사용하는 편이 정확도 등의 측면에서는 더 나음을 보여준다.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/machine-learning/'>Machine Learning</a>, <a href='/categories/paper/'>Paper</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=논문 리뷰 - Image-to-Image Translation with Conditional Adversarial Networks - 🍗 양념치킨 🍗&url=https://kejdev.github.io/posts/pix2pix/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=논문 리뷰 - Image-to-Image Translation with Conditional Adversarial Networks - 🍗 양념치킨 🍗&u=https://kejdev.github.io/posts/pix2pix/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=논문 리뷰 - Image-to-Image Translation with Conditional Adversarial Networks - 🍗 양념치킨 🍗&url=https://kejdev.github.io/posts/pix2pix/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://kejdev.github.io/posts/pix2pix/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8" style="margin:0 auto; margin-top:25px; max-width: 850px; padding:0px 30px"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div class="post-navigation d-flex justify-content-between"> <a href="/posts/python-open-api/" class="btn btn-outline-primary" prompt="Older"><p>간단하게 오픈 API 사용하기</p></a> <a href="/posts/U-Net(3D)/" class="btn btn-outline-primary" prompt="Newer"><p>논문 리뷰 - 3D U-Net Learning Dense Volumetric Segmentation from Sparse Annotation</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://www.instagram.com/ao_ej125">kejdev</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://kejdev.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
