<!DOCTYPE html>



<html lang="en" 
  
    mode="light"
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  
    <meta name="pv-cache-enabled" content="false">

    
  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="파이썬으로 모든 신문사 웹스크롤링 스크립트 만들기" />
<meta name="author" content="KEJdev" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="저번에 중앙일보와 한계례 신문사를 저번에 웹 스크롤링하는 것을 했습니다. 두번정도 해보니까 이제 슬슬 감이 잡히지 않던가요 ? 링크랑 기사내용 태그만 확인하면 스크롤링 되는 것을 확인 했으니, 이번엔 그냥 전체 신문사에서 선택해서 스크롤링하는 스크립트를 짜볼까합니다." />
<meta property="og:description" content="저번에 중앙일보와 한계례 신문사를 저번에 웹 스크롤링하는 것을 했습니다. 두번정도 해보니까 이제 슬슬 감이 잡히지 않던가요 ? 링크랑 기사내용 태그만 확인하면 스크롤링 되는 것을 확인 했으니, 이번엔 그냥 전체 신문사에서 선택해서 스크롤링하는 스크립트를 짜볼까합니다." />
<link rel="canonical" href="http://localhost:4000/posts/python-web5/" />
<meta property="og:url" content="http://localhost:4000/posts/python-web5/" />
<meta property="og:site_name" content="🍗 양념치킨 🍗" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-15T20:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="파이썬으로 모든 신문사 웹스크롤링 스크립트 만들기" />
<meta name="google-site-verification" content="google_meta_tag_verification" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"KEJdev"},"dateModified":"2022-08-02T23:27:54+08:00","datePublished":"2020-03-15T20:00:00+08:00","description":"저번에 중앙일보와 한계례 신문사를 저번에 웹 스크롤링하는 것을 했습니다. 두번정도 해보니까 이제 슬슬 감이 잡히지 않던가요 ? 링크랑 기사내용 태그만 확인하면 스크롤링 되는 것을 확인 했으니, 이번엔 그냥 전체 신문사에서 선택해서 스크롤링하는 스크립트를 짜볼까합니다.","headline":"파이썬으로 모든 신문사 웹스크롤링 스크립트 만들기","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/python-web5/"},"url":"http://localhost:4000/posts/python-web5/"}</script>
<!-- End Jekyll SEO tag -->


  <title>파이썬으로 모든 신문사 웹스크롤링 스크립트 만들기 | 🍗 양념치킨 🍗
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://www.favicon-generator.org/
-->



<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">
<link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">

<!-- <link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png">
<link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"> -->
<!-- <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png">

<link rel="icon" type="image/png" sizes="192x192"  href="/assets/img/favicons/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"> -->

<link rel="manifest" href="/assets/img/favicons/manifest.json">
<meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'> 
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="/assets/img/favicons/favicon.png">
<meta name="theme-color" content="#ffffff">


  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com">

  <!-- GA -->
  

  <!-- jsDelivr CDN -->
  <link rel="preconnect" href="cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="cdn.jsdelivr.net">

  <!-- Bootstrap -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
    integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous">

  <!-- Font Awesome -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"
    integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ="
    crossorigin="anonymous">

  <!--
  CSS selector for site.
-->

<link rel="stylesheet" href="/assets/css/style.css">


  <link rel="stylesheet" 
  href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css">



  <!-- JavaScripts -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

  <script defer
    src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script>

  <!--
  JS selector for site.
-->


  





<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>





</head>


  <body data-spy="scroll" data-target="#toc">

    <!--
  The Side Bar
-->

<div id="sidebar" style="width:190px" class="d-flex flex-column align-items-end">

  <div class="profile-wrapper text-center">
    <div style="display:flex">
      <div id="avatar" style="margin:0 auto 0 auto;">
        <a href="/" alt="avatar" class="mx-auto">
          
          <img style="max-width:100%;" src="/assets/img/favicons/mycat.jpg" alt="avatar" onerror="this.style.display='none'">
        </a>
      </div>
    </div>

    <div style="display:flex">
      <div style="margin:0 auto 0 auto; font-weight:550px;" >
        <a href="/">🍗 양념치킨 🍗</a>
      </div>
    </div>

    <div style="display:flex">
      <div class="site-subtitle font-italic"  style="margin:0 auto 0 auto;">고양이 좋아하는 개발자</div>
    </div>
  </div><!-- .profile-wrapper -->

  <ul class="w-100">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/tabs/categories/" class="nav-link">
        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tabs/archives/" class="nav-link">
        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tabs/about/" class="nav-link">
        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center">

    


  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <div id="main-wrapper">
      <div id="main">

        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->


<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->


<!-- Add attribute 'hide-bullet' to the checkbox list -->




  

  

  <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->
  
  

  

  



<!-- return -->
<div class="row">

  <div id="post-wrapper" class="col-12 col-lg-11 col-xl-8">

    <div class="post-content" style="margin-top:70px;">

      <h1 data-toc-skip>파이썬으로 모든 신문사 웹스크롤링 스크립트 만들기</h1>

      <div class="post-meta text-muted d-flex flex-column" style="border-bottom:1px solid black;" >
        <!-- Published date and author -->
        <div >
          <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Sun, Mar 15, 2020,  8:00 PM +0800"
  >

  
  

  
    Mar 15, 2020
  

  <i class="unloaded">2020-03-15T20:00:00+08:00</i>

</span>

          by
          <span class="author">
            KEJdev
          </span>
        </div>        
        <div>
          <!-- lastmod -->
          
          <span>
            Updated
            <!--
  Date format snippet
-->





<span class="timeago lastmod"
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Wed, Aug  3, 2022, 12:27 AM +0900"
  >

  
  

  
    Aug  3
  

  <i class="unloaded">2022-08-02T23:27:54+08:00</i>

</span>

          </span>
          

          <!-- read time -->
          <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="저번에 중앙일보와 한계례 신문사를 저번에 웹 스크롤링하는 것을 했습니다. 두번정도 해보니까 이제 슬슬 감이 잡히지 않던가요 ? 링크랑 기사내용 태그만 확인하면 스크롤링 되는 것을 확인 했으니, 이번엔 그냥 전체 신문사에서 선택해서 스크롤링하는 스크립트를 짜볼까합니다.

웹 스크롤링 함수 구현

우선 자신의 컴퓨터 user-agent를 확인해야합니다. 여기를 눌러 자신의 agent를 꼭 확인합니다.

우리는 메인 함수와 서브 함수 두가지를 우선 만들어야 합니다. 메인 함수는 스크롤링한 text를 리턴하는 함수를 만들고, 서브 함수는 두 가지 정도를 만들려고 합니다. 서브 함수는 기사 상세 url과 기사 text를 리스트를 append시키는 함수, 그리고 url를 입력받아 html로 변환하고 beautiful soup에서 사용할수 있도록 설정하는 함수를 만들겠습니다.

우선 서브 함수로 url를 받아서 html로 변화하는 함수를 만들겠습니다.

1
2
3
4
5
6
7
8
import urllib.request as rq
from bs4 import BeautifulSoup

def start(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36',}
    url = rq.Request(url, headers = headers)
    res = rq.urlopen(url).read()
return BeautifulSoup(res, "html.parser")


그리고 기사 url과 기사 text를 리스트에 담는 함수를 작성합니다.

1
2
3
4
5
def news_fetch(url, tag):
    soup = start(url)

    for link in soup.select(tag[1]):
    result.append(link.get_text())


그리고 메인 함수인 스크롤링한 text를 리턴하는 함수를 작성합니다.

1
2
3
4
5
6
7
8
def fetch_list_url(url, tag):
    global result
    soup = start(url)

    for link in soup.select(tag[0]):
        result.append(link.get_text())
        print('link =' ,link['href'], link.get_text())
        news_fetch(link['href'], tag)


이제 가장 중요한 url링크와 기사 내용을 스크롤링해야 할 태그 부분을 가져옵니다.



1
2
result = []
url_list = ['http://search.daum.net/search?w=news&amp;q={search}&amp;spacing=0&amp;p={page}&amp;cp=16ZHEMAarrmZlVrZG3&amp;cpname=%EB%94%94%EC%A7%80%ED%84%B8%ED%83%80%EC%9E%84%EC%8A%A4', ["#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div &gt; div &gt; a", "#resizeContents &gt; div"]]




여기서 이제 주소 끝 부분에 ‘디지털 타임즈’가 아니라 각종 신문사를 넣어 링크를 여러개 만들어 전체 신문사를 스크롤링 스크립트를 작성하려고 합니다.

전체 신문사 기사 스크롤링

신문사를 선택해서 스크롤링 하는 최종 코드는 아래와 같습니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
import urllib.request as rq
from bs4 import BeautifulSoup
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
from os import path
import re

def start(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36',}
    url = rq.Request(url, headers = headers)
    res = rq.urlopen(url).read()
    return BeautifulSoup(res, "html.parser")

def fetch_list_url(url, tag):
    global result
    soup = start(url)
    for link in soup.select(tag[0]):
        result.append(link.get_text())
        print('link =', link['href'], link.get_text())
        news_fetch(link['href'], tag)

def news_fetch(url, tag):
    soup = start(url)
    for link in soup.select(tag[1]):
        result.append(link.get_text())

result = []
search_text = str(input("검색어를 입력하세요 : ").encode("utf-8"))[2:-1].replace('\\x', '%')

def numbers_to_strings():
    num = input('1 : 전자신문 \n2 : 디지털 타임즈 \n3 : 경향신문 \n4 : 중앙일보 \n5 : 동아일보 \n6 : 조선일보\n')

    switcher = {
        1: ['http://search.daum.net/search?w=news&amp;q={search}&amp;spacing=0&amp;p={page}&amp;cp=16yGc-mR1Rz5JT4-UZ&amp;cpname=%EC%A0%84%EC%9E%90%EC%8B%A0%EB%AC%B8&amp;DA=PGD', ["#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div &gt; div &gt; a", "#articleBody &gt; p"]],
        2: ['http://search.daum.net/search?w=news&amp;q={search}&amp;spacing=0&amp;p={page}&amp;cp=16ZHEMAarrmZlVrZG3&amp;cpname=%EB%94%94%EC%A7%80%ED%84%B8%ED%83%80%EC%9E%84%EC%8A%A4', ["#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div &gt; div &gt; a", "#resizeContents &gt; div"]],
        3: ['http://search.daum.net/search?w=news&amp;q={search}&amp;spacing=0&amp;p={page}&amp;cp=16bfGN9mQcFhOx4F5l&amp;cpname=%EA%B2%BD%ED%96%A5%EC%8B%A0%EB%AC%B8', ["#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div &gt; div &gt; a", "#container &gt; div.main_container &gt; div.art_cont &gt; div.art_body &gt; p"]],
        4: ['http://search.daum.net/search?nil_suggest=btn&amp;w=news&amp;cluster=y&amp;q={search}&amp;cp=16nfco03BTHhdjCcTS&amp;cpname=%EC%A4%91%EC%95%99%EC%9D%BC%EB%B3%B4&amp;p={page}',["#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div.cont_inner &gt; div &gt; a " ,"#article_body"]],
        5: ['http://search.daum.net/search?w=news&amp;nil_search=btn&amp;enc=utf8&amp;cluster=y&amp;cluster_page=1&amp;q=AI&amp;cp=16Et2OLVVtHab8gcjE&amp;cpname={search}&amp;DA=PGD&amp;p={page}',["#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div.cont_inner &gt; div &gt; a " , "div.article_txt "]],
        6: ['http://search.daum.net/search?w=news&amp;nil_search=btn&amp;enc=utf8&amp;cluster=y&amp;cluster_page=1&amp;q=AI&amp;cp=16EeZKAuilXKH5dzIt&amp;cpname={search}&amp;p={page}',["#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div.cont_inner &gt; div &gt; a ","div.par"]]
    }
    return switcher.get(int(num), "nothing")

url_list = numbers_to_strings()

for i in range(1, 2):
    url, tag = url_list[0].format(search=search_text, page=i), url_list[1]
    fetch_list_url(url, tag)
    
print(result)

f = open('data3.txt', 'w', encoding='UTF-8')
f.writelines(result)
f.close()




여기서 알아둬야 할 점은, 신문사 같은 경우는 웹 스크롤링하는 사람이 꽤 있다고 들어서 신문사들도 태그나 URL를 바꾸는 경우도 있다고 합니다. 그래서 현재 작성된 코드가 지금은 돌아가더라도 시간이 지난 뒤에는 안돌아갈 수 있으니 이 부분을 꼭 참고하셔서 작성하셔야합니다.
 words">1 min</span> -->


          <!-- page views -->
          

        </div>

      </div> <!-- .post-meta -->

      <div class="post-content">

        

        <p>저번에 중앙일보와 한계례 신문사를 저번에 웹 스크롤링하는 것을 했습니다. 두번정도 해보니까 이제 슬슬 감이 잡히지 않던가요 ? 링크랑 기사내용 태그만 확인하면 스크롤링 되는 것을 확인 했으니, 이번엔 그냥 전체 신문사에서 선택해서 스크롤링하는 스크립트를 짜볼까합니다.</p>

<h2 id="웹-스크롤링-함수-구현">웹 스크롤링 함수 구현</h2>

<p>우선 자신의 컴퓨터 user-agent를 확인해야합니다. <a href="https://www.whoishostingthis.com/tools/user-agent/">여기</a>를 눌러 자신의 agent를 꼭 확인합니다.</p>

<p>우리는 메인 함수와 서브 함수 두가지를 우선 만들어야 합니다. 메인 함수는 스크롤링한 text를 리턴하는 함수를 만들고, 서브 함수는 두 가지 정도를 만들려고 합니다. 서브 함수는 기사 상세 url과 기사 text를 리스트를 append시키는 함수, 그리고 url를 입력받아 html로 변환하고 beautiful soup에서 사용할수 있도록 설정하는 함수를 만들겠습니다.</p>

<p>우선 서브 함수로 url를 받아서 html로 변화하는 함수를 만들겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">urllib.request</span> <span class="k">as</span> <span class="n">rq</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span><span class="p">,}</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">rq</span><span class="p">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">rq</span><span class="p">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">).</span><span class="n">read</span><span class="p">()</span>
<span class="k">return</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="s">"html.parser"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>그리고 기사 url과 기사 text를 리스트에 담는 함수를 작성합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">news_fetch</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">tag</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">start</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">soup</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">tag</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">link</span><span class="p">.</span><span class="n">get_text</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></div></div>

<p>그리고 메인 함수인 스크롤링한 text를 리턴하는 함수를 작성합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">fetch_list_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">tag</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">result</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">start</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">soup</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">tag</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">link</span><span class="p">.</span><span class="n">get_text</span><span class="p">())</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'link ='</span> <span class="p">,</span><span class="n">link</span><span class="p">[</span><span class="s">'href'</span><span class="p">],</span> <span class="n">link</span><span class="p">.</span><span class="n">get_text</span><span class="p">())</span>
        <span class="n">news_fetch</span><span class="p">(</span><span class="n">link</span><span class="p">[</span><span class="s">'href'</span><span class="p">],</span> <span class="n">tag</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>이제 가장 중요한 url링크와 기사 내용을 스크롤링해야 할 태그 부분을 가져옵니다.</p>

<center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets//images/web9.png" /></center>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">url_list</span> <span class="o">=</span> <span class="p">[</span><span class="s">'http://search.daum.net/search?w=news&amp;q={search}&amp;spacing=0&amp;p={page}&amp;cp=16ZHEMAarrmZlVrZG3&amp;cpname=%EB%94%94%EC%A7%80%ED%84%B8%ED%83%80%EC%9E%84%EC%8A%A4'</span><span class="p">,</span> <span class="p">[</span><span class="s">"#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div &gt; div &gt; a"</span><span class="p">,</span> <span class="s">"#resizeContents &gt; div"</span><span class="p">]]</span>
</pre></td></tr></tbody></table></code></div></div>

<center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets//images/web10.png" /></center>

<p>여기서 이제 주소 끝 부분에 ‘디지털 타임즈’가 아니라 각종 신문사를 넣어 링크를 여러개 만들어 전체 신문사를 스크롤링 스크립트를 작성하려고 합니다.</p>

<h2 id="전체-신문사-기사-스크롤링">전체 신문사 기사 스크롤링</h2>

<p>신문사를 선택해서 스크롤링 하는 최종 코드는 아래와 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">urllib.request</span> <span class="k">as</span> <span class="n">rq</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span><span class="p">,</span> <span class="n">STOPWORDS</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">path</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span><span class="p">,}</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">rq</span><span class="p">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">rq</span><span class="p">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">).</span><span class="n">read</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="s">"html.parser"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fetch_list_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">tag</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">result</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">start</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">soup</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">tag</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">link</span><span class="p">.</span><span class="n">get_text</span><span class="p">())</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'link ='</span><span class="p">,</span> <span class="n">link</span><span class="p">[</span><span class="s">'href'</span><span class="p">],</span> <span class="n">link</span><span class="p">.</span><span class="n">get_text</span><span class="p">())</span>
        <span class="n">news_fetch</span><span class="p">(</span><span class="n">link</span><span class="p">[</span><span class="s">'href'</span><span class="p">],</span> <span class="n">tag</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">news_fetch</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">tag</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">start</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">soup</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">tag</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">link</span><span class="p">.</span><span class="n">get_text</span><span class="p">())</span>

<span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">search_text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">input</span><span class="p">(</span><span class="s">"검색어를 입력하세요 : "</span><span class="p">).</span><span class="n">encode</span><span class="p">(</span><span class="s">"utf-8"</span><span class="p">))[</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="s">'</span><span class="se">\\</span><span class="s">x'</span><span class="p">,</span> <span class="s">'%'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">numbers_to_strings</span><span class="p">():</span>
    <span class="n">num</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s">'1 : 전자신문 </span><span class="se">\n</span><span class="s">2 : 디지털 타임즈 </span><span class="se">\n</span><span class="s">3 : 경향신문 </span><span class="se">\n</span><span class="s">4 : 중앙일보 </span><span class="se">\n</span><span class="s">5 : 동아일보 </span><span class="se">\n</span><span class="s">6 : 조선일보</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

    <span class="n">switcher</span> <span class="o">=</span> <span class="p">{</span>
        <span class="mi">1</span><span class="p">:</span> <span class="p">[</span><span class="s">'http://search.daum.net/search?w=news&amp;q={search}&amp;spacing=0&amp;p={page}&amp;cp=16yGc-mR1Rz5JT4-UZ&amp;cpname=%EC%A0%84%EC%9E%90%EC%8B%A0%EB%AC%B8&amp;DA=PGD'</span><span class="p">,</span> <span class="p">[</span><span class="s">"#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div &gt; div &gt; a"</span><span class="p">,</span> <span class="s">"#articleBody &gt; p"</span><span class="p">]],</span>
        <span class="mi">2</span><span class="p">:</span> <span class="p">[</span><span class="s">'http://search.daum.net/search?w=news&amp;q={search}&amp;spacing=0&amp;p={page}&amp;cp=16ZHEMAarrmZlVrZG3&amp;cpname=%EB%94%94%EC%A7%80%ED%84%B8%ED%83%80%EC%9E%84%EC%8A%A4'</span><span class="p">,</span> <span class="p">[</span><span class="s">"#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div &gt; div &gt; a"</span><span class="p">,</span> <span class="s">"#resizeContents &gt; div"</span><span class="p">]],</span>
        <span class="mi">3</span><span class="p">:</span> <span class="p">[</span><span class="s">'http://search.daum.net/search?w=news&amp;q={search}&amp;spacing=0&amp;p={page}&amp;cp=16bfGN9mQcFhOx4F5l&amp;cpname=%EA%B2%BD%ED%96%A5%EC%8B%A0%EB%AC%B8'</span><span class="p">,</span> <span class="p">[</span><span class="s">"#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div &gt; div &gt; a"</span><span class="p">,</span> <span class="s">"#container &gt; div.main_container &gt; div.art_cont &gt; div.art_body &gt; p"</span><span class="p">]],</span>
        <span class="mi">4</span><span class="p">:</span> <span class="p">[</span><span class="s">'http://search.daum.net/search?nil_suggest=btn&amp;w=news&amp;cluster=y&amp;q={search}&amp;cp=16nfco03BTHhdjCcTS&amp;cpname=%EC%A4%91%EC%95%99%EC%9D%BC%EB%B3%B4&amp;p={page}'</span><span class="p">,[</span><span class="s">"#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div.cont_inner &gt; div &gt; a "</span> <span class="p">,</span><span class="s">"#article_body"</span><span class="p">]],</span>
        <span class="mi">5</span><span class="p">:</span> <span class="p">[</span><span class="s">'http://search.daum.net/search?w=news&amp;nil_search=btn&amp;enc=utf8&amp;cluster=y&amp;cluster_page=1&amp;q=AI&amp;cp=16Et2OLVVtHab8gcjE&amp;cpname={search}&amp;DA=PGD&amp;p={page}'</span><span class="p">,[</span><span class="s">"#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div.cont_inner &gt; div &gt; a "</span> <span class="p">,</span> <span class="s">"div.article_txt "</span><span class="p">]],</span>
        <span class="mi">6</span><span class="p">:</span> <span class="p">[</span><span class="s">'http://search.daum.net/search?w=news&amp;nil_search=btn&amp;enc=utf8&amp;cluster=y&amp;cluster_page=1&amp;q=AI&amp;cp=16EeZKAuilXKH5dzIt&amp;cpname={search}&amp;p={page}'</span><span class="p">,[</span><span class="s">"#clusterResultUL &gt; li &gt; div.wrap_cont &gt; div.cont_inner &gt; div &gt; a "</span><span class="p">,</span><span class="s">"div.par"</span><span class="p">]]</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">switcher</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num</span><span class="p">),</span> <span class="s">"nothing"</span><span class="p">)</span>

<span class="n">url_list</span> <span class="o">=</span> <span class="n">numbers_to_strings</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
    <span class="n">url</span><span class="p">,</span> <span class="n">tag</span> <span class="o">=</span> <span class="n">url_list</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nb">format</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">search_text</span><span class="p">,</span> <span class="n">page</span><span class="o">=</span><span class="n">i</span><span class="p">),</span> <span class="n">url_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">fetch_list_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">tag</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">'data3.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'UTF-8'</span><span class="p">)</span>
<span class="n">f</span><span class="p">.</span><span class="n">writelines</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="n">f</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<center><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets//images/web11.png" /></center>

<p>여기서 알아둬야 할 점은, 신문사 같은 경우는 웹 스크롤링하는 사람이 꽤 있다고 들어서 신문사들도 태그나 URL를 바꾸는 경우도 있다고 합니다. 그래서 현재 작성된 코드가 지금은 돌아가더라도 시간이 지난 뒤에는 안돌아갈 수 있으니 이 부분을 꼭 참고하셔서 작성하셔야합니다.</p>


      </div>

      <div class="post-tail-wrapper text-muted">

        <!-- categories -->
        <!-- 
        <div class="post-meta mb-3">
          <i class="far fa-folder-open fa-fw mr-1"></i>
          
            <a href='/categories/program-language/'>Program Language</a>,
            <a href='/categories/python/'>Python</a>
        </div>
         -->

        <!-- tags -->
        <!--  -->

        <div class="post-tail-bottom
          d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
          
          <div class="license-wrapper">
            This post is licensed under
            <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>
            by the author.
          </div>
          

          <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=파이썬으로 모든 신문사 웹스크롤링 스크립트 만들기 - 🍗 양념치킨 🍗&url=http://localhost:4000/posts/python-web5/" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=파이썬으로 모든 신문사 웹스크롤링 스크립트 만들기 - 🍗 양념치킨 🍗&u=http://localhost:4000/posts/python-web5/" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://telegram.me/share?text=파이썬으로 모든 신문사 웹스크롤링 스크립트 만들기 - 🍗 양념치킨 🍗&url=http://localhost:4000/posts/python-web5/" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    
      
        <a href="https://www.linkedin.com/sharing/share-offsite/?url=http://localhost:4000/posts/python-web5/" data-toggle="tooltip" data-placement="top"
          title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin">
          <i class="fa-fw fab fa-linkedin"></i>
        </a>
    

    <i class="fa-fw fas fa-link small" onclick="copyLink()"
        data-toggle="tooltip" data-placement="top" title="Copy link"></i>

  </span>
</div>


        </div><!-- .post-tail-bottom -->

      </div>

    </div> <!-- .post -->


  </div> <!-- #post-wrapper -->

  

  

  <!--
  The Pannel on right side (Desktop views)
-->


</div> <!-- .row -->

<div class="row">
  <div class="col-12 col-lg-11 col-xl-8" 
    style="margin:0 auto; margin-top:25px; max-width: 850px; padding:0px 30px">
    <div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">

    <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->




    <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/posts/python-web4/" class="btn btn-outline-primary"
    prompt="Older">
    <p>J사 신문사 웹스크롤링 하기</p>
  </a>
  

  
  <a href="/posts/python-web6/" class="btn btn-outline-primary"
    prompt="Newer">
    <p>네이버에서 이미지 크롤링하기</p>
  </a>
  

</div>


    <!--  -->

    </div>

  </div> <!-- .col-* -->

</div> <!-- .row -->


  <!--
  image lazy load: https://github.com/ApoorvSaxena/lozad.js
-->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script>

<script type="text/javascript">
  const imgs = document.querySelectorAll('.post-content img');
  const observer = lozad(imgs);
  observer.observe();
</script>




        <!--
  The Footer
-->

<footer class="d-flex w-100 justify-content-center">
  <div class="d-flex justify-content-between align-items-center">
    <div class="footer-left">
      <p class="mb-0">
        © 2022
        <a href="https://www.instagram.com/ao_ej125">kejdev</a>.
        
        <span data-toggle="tooltip" data-placement="top"
          title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
        
      </p>
    </div>

    <div class="footer-right">
      <p class="mb-0">
        Powered by
        <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
        with
        <a href="https://github.com/cotes2020/jekyll-theme-chirpy"
          target="_blank" rel="noopener">Chirpy</a>
        theme.
      </p>
    </div>

  </div> <!-- div.d-flex -->
</footer>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-xl-11 post-content">
    <div id="search-hints">
      <h4 class="text-muted mb-4">Trending Tags</h4>

      

















      

    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    
      <!--
  mermaid-js loader
-->

<script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script>
<script>
  $(function() {
    let initTheme = "default";

    if ($("html[mode=dark]").length > 0
      || ($("html[mode]").length == 0
        && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) {
      initTheme = "dark";
    }

    let mermaidConf = {
      theme: initTheme  /* <default|dark|forest|neutral> */
    };

    /* Markdown converts to HTML */
    $("pre").has("code.language-mermaid").each(function() {
      let svgCode = $(this).children().html();
      $(this).addClass("unloaded");
      $(this).after(`<div class=\"mermaid\">${svgCode}</div>`);
    });

    mermaid.initialize(mermaidConf);
  });
</script>

    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    <!--
  Jekyll Simple Search loader
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="http://localhost:4000{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    <div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div>    <div><i class="fa fa-tag fa-fw"></i>{tags}</div>  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No result founds.</p>'
});
</script>


  </body>

</html>

