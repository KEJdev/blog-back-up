<!DOCTYPE html>



<html lang="en" 
  
    mode="light"
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  
    <meta name="pv-cache-enabled" content="false">

    
  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="íŒŒì´ì¬ í´ë˜ìŠ¤ë¡œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°(cross_entropy, softmax, Softmax With loss )" />
<meta name="author" content="KEJdev" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="ì €ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” forwardì™€ backward ê·¸ë¦¬ê³  í™œì„±í™” í•¨ìˆ˜ì¸ Reluí•¨ìˆ˜ë¥¼ í´ë˜ìŠ¤ë¡œ êµ¬í˜„í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” cross entropyì™€ softmaxë„ í•¨ê»˜ êµ¬í˜„í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤." />
<meta property="og:description" content="ì €ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” forwardì™€ backward ê·¸ë¦¬ê³  í™œì„±í™” í•¨ìˆ˜ì¸ Reluí•¨ìˆ˜ë¥¼ í´ë˜ìŠ¤ë¡œ êµ¬í˜„í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” cross entropyì™€ softmaxë„ í•¨ê»˜ êµ¬í˜„í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤." />
<link rel="canonical" href="http://localhost:4000/posts/ml-class-softmax/" />
<meta property="og:url" content="http://localhost:4000/posts/ml-class-softmax/" />
<meta property="og:site_name" content="ğŸ— ì–‘ë…ì¹˜í‚¨ ğŸ—" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-01-18T14:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="íŒŒì´ì¬ í´ë˜ìŠ¤ë¡œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°(cross_entropy, softmax, Softmax With loss )" />
<meta name="google-site-verification" content="google_meta_tag_verification" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"KEJdev"},"dateModified":"2022-08-02T23:27:54+08:00","datePublished":"2020-01-18T14:00:00+08:00","description":"ì €ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” forwardì™€ backward ê·¸ë¦¬ê³  í™œì„±í™” í•¨ìˆ˜ì¸ Reluí•¨ìˆ˜ë¥¼ í´ë˜ìŠ¤ë¡œ êµ¬í˜„í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” cross entropyì™€ softmaxë„ í•¨ê»˜ êµ¬í˜„í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.","headline":"íŒŒì´ì¬ í´ë˜ìŠ¤ë¡œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°(cross_entropy, softmax, Softmax With loss )","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/ml-class-softmax/"},"url":"http://localhost:4000/posts/ml-class-softmax/"}</script>
<!-- End Jekyll SEO tag -->


  <title>íŒŒì´ì¬ í´ë˜ìŠ¤ë¡œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°(cross_entropy, softmax, Softmax With loss ) | ğŸ— ì–‘ë…ì¹˜í‚¨ ğŸ—
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://www.favicon-generator.org/
-->



<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">
<link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">

<!-- <link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png">
<link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"> -->
<!-- <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png">

<link rel="icon" type="image/png" sizes="192x192"  href="/assets/img/favicons/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"> -->

<link rel="manifest" href="/assets/img/favicons/manifest.json">
<meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'> 
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="/assets/img/favicons/favicon.png">
<meta name="theme-color" content="#ffffff">


  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com">

  <!-- GA -->
  

  <!-- jsDelivr CDN -->
  <link rel="preconnect" href="cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="cdn.jsdelivr.net">

  <!-- Bootstrap -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
    integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous">

  <!-- Font Awesome -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"
    integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ="
    crossorigin="anonymous">

  <!--
  CSS selector for site.
-->

<link rel="stylesheet" href="/assets/css/style.css">


  <link rel="stylesheet" 
  href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css">



  <!-- JavaScripts -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

  <script defer
    src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script>

  <!--
  JS selector for site.
-->


  





<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>





</head>


  <body data-spy="scroll" data-target="#toc">

    <!--
  The Side Bar
-->

<div id="sidebar" style="width:190px" class="d-flex flex-column align-items-end">

  <div class="profile-wrapper text-center">
    <div style="display:flex">
      <div id="avatar" style="margin:0 auto 0 auto;">
        <a href="/" alt="avatar" class="mx-auto">
          
          <img style="max-width:100%;" src="/assets/img/favicons/mycat.jpg" alt="avatar" onerror="this.style.display='none'">
        </a>
      </div>
    </div>

    <div style="display:flex">
      <div style="margin:0 auto 0 auto; font-weight:550px;" >
        <a href="/">ğŸ— ì–‘ë…ì¹˜í‚¨ ğŸ—</a>
      </div>
    </div>

    <div style="display:flex">
      <div class="site-subtitle font-italic"  style="margin:0 auto 0 auto;">ê³ ì–‘ì´ ì¢‹ì•„í•˜ëŠ” ê°œë°œì</div>
    </div>
  </div><!-- .profile-wrapper -->

  <ul class="w-100">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/tabs/categories/" class="nav-link">
        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tabs/archives/" class="nav-link">
        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tabs/about/" class="nav-link">
        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center">

    


  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <div id="main-wrapper">
      <div id="main">

        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->


<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->


<!-- Add attribute 'hide-bullet' to the checkbox list -->




  

  

  <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->
  
  

  

  



<!-- return -->
<div class="row">

  <div id="post-wrapper" class="col-12 col-lg-11 col-xl-8">

    <div class="post-content" style="margin-top:70px;">

      <h1 data-toc-skip>íŒŒì´ì¬ í´ë˜ìŠ¤ë¡œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°(cross_entropy, softmax, Softmax With loss )</h1>

      <div class="post-meta text-muted d-flex flex-column" style="border-bottom:1px solid black;" >
        <!-- Published date and author -->
        <div >
          <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Sat, Jan 18, 2020,  2:00 PM +0800"
  >

  
  

  
    Jan 18, 2020
  

  <i class="unloaded">2020-01-18T14:00:00+08:00</i>

</span>

          by
          <span class="author">
            KEJdev
          </span>
        </div>        
        <div>
          <!-- lastmod -->
          
          <span>
            Updated
            <!--
  Date format snippet
-->





<span class="timeago lastmod"
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Wed, Aug  3, 2022, 12:27 AM +0900"
  >

  
  

  
    Aug  3
  

  <i class="unloaded">2022-08-02T23:27:54+08:00</i>

</span>

          </span>
          

          <!-- read time -->
          <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="ì €ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” forwardì™€ backward ê·¸ë¦¬ê³  í™œì„±í™” í•¨ìˆ˜ì¸ Reluí•¨ìˆ˜ë¥¼ í´ë˜ìŠ¤ë¡œ êµ¬í˜„í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” cross entropyì™€ softmaxë„ í•¨ê»˜ êµ¬í˜„í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

cross entropy ì™€ softmax

ë³´í†µ ì‹ ê²½ë§ì—ì„œ ë¶„ë¥˜í•  ë•Œ, softmaxë¥¼ ì‚¬ìš©í•˜ë©°, softmaxëŠ” ì‹ ê²½ë§ì˜ ì¶œë ¥ì¸µ ë§ˆì§€ë§‰ì—ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤. softmaxì— ê´€í•œ ë” ìì„¸í•œ ì„¤ëª…ì€ ì—¬ê¸°ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. softmaxì™€ í•¨ê»˜ ì˜¤ì°¨ í•¨ìˆ˜ë¡œ cross entropyí•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, cross entropy errorëŠ” ì¤„ì—¬ì„œ CEEë¼ê³ ë„ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

\[E\quad =-\sum _{ k }{ { t }_{ k } } { log\, y }_{ k }\quad\]

\(y_k\)ëŠ” ì‹ ê²½ë§ì—ì„œ ë‚˜ì˜¤ëŠ” ì¶œë ¥ ê°’ì´ë©° 0ì—ì„œ 1ì‚¬ì´ì˜ ê°’ì´ ë‚˜ì˜µë‹ˆë‹¤. $t_k$ëŠ” ì •ë‹µ ë ˆì´ë¸”ì´ë©°, ì •ë‹µì´ ì•„ë‹Œ ë‚˜ë¨¸ì§€ \(t_k\)ê°€ 0ì´ë©°, \(log\)ëŠ” ë°‘ì´ \(e\)ì¸ ìì—°ë¡œê·¸ì…ë‹ˆë‹¤. cross entropyë¥¼ Pythonìœ¼ë¡œ ì‘ì„±í•  ë•Œ ì•„ì£¼ ì‘ì€ ê°’ì„ ë”í•´ì¤˜ì•¼ í•˜ëŠ”ë°, ê·¸ ì´ìœ ëŠ” yê°€ 0ì¸ ê²½ìš° -infê°’ì„ ì˜ˆë°©í•˜ê¸° ìœ„í•´ì„œ ì…ë‹ˆë‹¤.

íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1
2
3
4
import numpy as np

def crossEntropyError(y, t):
    return -np.sum(t*np.log(y))


ê·¸ëŸ¬ë‚˜ ìœ„ì™€ ê°™ì´ êµ¬í˜„í•˜ê²Œ ëœë‹¤ë©´, \(y\)ê°€ \(0\)ë˜ë²„ë¦¬ëŠ” ê²½ìš°ì— -infê°’ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•„ì£¼ ì‘ì€ ê°’ì„ ë”í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤.

1
2
3
4
5
import numpy as np

def crossEntropyError(y, t):
    delta = 1e-7 #ì•„ì£¼ ì‘ì€ ê°’ (yê°€ 0ì¸ ê²½ìš° -inf ê°’ì„ ì˜ˆë°©)
    return -np.sum(t*np.log(y+delta))


ê·¸ë˜ì„œ cross entropyë¥¼ êµ¬í˜„í•  ë•ŒëŠ” ìœ„ì™€ ê°™ì´ ì•„ì£¼ ì‘ì€ ê°’ì„ $y$ì— ë”í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
import numpy as np

def crossEntropyError(y, t):
    delta = 1e-7 
    return -np.sum(t*np.log(y+delta))

t = np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]) # label = 5
y = np.array([0.1, 0.03, 0.05, 0.2, 0.9, 0.0, 0.1, 0.2, 0.12, 0.03])

print("-- ì •ë‹µì¸ ê²½ìš° --")
print("CEE :", crossEntropyError(y, t))

y = np.array([0.1, 0.03, 0.05, 0.2, 0.0, 0.1, 0.2, 0.12, 0.03, 0.9])
print("-- ì˜¤ë¥˜ì¸ ê²½ìš° --")
print("CEE :", crossEntropyError(y, t))


softmaxëŠ” ì•„ë˜ì™€ ê°™ì´ íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1
2
3
4
5
6
def softmax(a):
    c = np.max(a)  
    exp_a = np.exp(a)
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y

Softmax With loss í´ë˜ìŠ¤ ë§Œë“¤ê¸°

í´ë˜ìŠ¤ ì´ë¦„ì€ ì›í•˜ëŠ” ê±¸ë¡œ í•˜ì…”ë„ ë˜ì§€ë§Œ, ì €ëŠ” ëª…í™•í•œ êµ¬ë¶„ì„ ìœ„í•´ ì´ë ‡ê²Œ ì§“ê² ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ softmaxì™€ cross entropy í•¨ìˆ˜ ë‘ê°œ ë‹¤ êµ¬í˜„í–ˆê¸° ë•Œë¬¸ì—, ì¶”ê°€ í•  í•¨ìˆ˜ëŠ” ì—†ìœ¼ë©° lossí•¨ìˆ˜ì— ëŒ€í•´ forwardì™€ backwardë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ë§Œ êµ¬í˜„í•˜ë©´ Softmax With loss í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
import numpy as np

def cross_entropy_error(y, t):
    delta = 1e-7  
    return -np.sum(t * np.log(y + delta)) / y.shape[0]

def softmax(a):
    c = np.max(a)  # ì¶”ê°€í•œ ë¶€ë¶„
    exp_a = np.exp(a)
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a

    return y

class SoftmaxWithloss:
    def __init__(self):
        self.loss = None
        self.y = None
        self.t = None

    def forward(self, x, t):
        self.t = t
        self.y = softmax(x)
        self.loss = cross_entropy_error(self.y, self.t)

        return self.loss

    def backward(self, dout=1):
        batch_size = self.t.shape[0]
        dx = (self.y - self.t) / batch_size

    return dx


SoftmaxWithlossí•¨ìˆ˜ ì•ˆì—ì„œ ì‚¬ìš©í•œ forwardì™€ backwardí•¨ìˆ˜ê°€ ì´í•´ê°€ ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì—¬ê¸°ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”. 
ì—¬ê¸°ê¹Œì§€ êµ¬í–ˆë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ 2ì¸µì§œë¦¬ ì‹ ê²½ë§ì„ ì‰½ê²Œ ë§Œë“¤ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
import numpy as np

def cross_entropy_error(y, t):
    delta = 1e-7 
    return -np.sum(t * np.log(y + delta)) / y.shape[0]

def softmax(a):
    c = np.max(a)  
    exp_a = np.exp(a)
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a

    return y


class Affine:
    def __init__(self, W, b):
        self.W = W
        self.b = b
        self.x = None
        self.dW = None
        self.db = None

    def forward(self, x):
        self.x = x
        out = np.dot(x, self.W) + self.b

        return out

    def backward(self, dout):
        dx = np.dot(dout, self.W.T)
        self.dW = np.dot(self.x.T, dout)
        self.db = np.sum(dout, axis=0)

        return dx, self.dW, self.db


class Relu:
    def __init__(self):
        self.mask = None

    def forward(self, x):
        self.mask = (x &lt;= 0)  # ì„¤ëª… : x ê°’ì´ 0 ì´í•˜ë©´ True í¬ë©´  False; True, False ë¥¼ ê°€ì§€ëŠ” numpy ë°°ì—´
        out = x.copy()
        out[self.mask] = 0  # ì„¤ëª… : mask ê°€ Ture ì¸ ê³³ì€ x ì˜ ì›ì†Œ ê°’ì´ 0, False ì¸ ê³³ì€ ê·¸ëŒ€ë¡œ ì¶œë ¥

        return out

    def backward(self, dout):
        dout[self.mask] = 0
        dx = dout
        return dx

class SoftmaxWithloss:
    def __init__(self):
        self.loss = None
        self.y = None
        self.t = None

    def forward(self, x, t):
        self.t = t
        self.y = softmax(x)
        self.loss = cross_entropy_error(self.y, self.t)

        return self.loss

    def backward(self, dout=1):
        batch_size = self.t.shape[0]
        dx = (self.y - self.t) / batch_size

        return dx

x = np.array([[1, 2]])
w1 = np.array([[1, 3, 5], [2, 4, 6]])
w2 = np.array([[1, 4], [2, 5], [3, 6]])
b1 = np.array([1, 2, 3])
b2 = np.array([1, 2])

# ìˆœì „íŒŒ
affine1 = Affine(w1, b1)
affine2 = Affine(w2, b2)
relu1 = Relu()
relu2 = Relu()

# ì€ë‹‰ 1ì¸µ
out1 = affine1.forward(x)
relu_out1 = relu1.forward(out1)

# ì€ë‹‰ 2ì¸µ
out2 = affine2.forward(relu_out1)
relu_out2 = relu2.forward(out2)
print('out : \n', relu_out2)

# softmax
t = np.array([[0, 1]])
softmaxWithloss = SoftmaxWithloss()
loss = softmaxWithloss.forward(relu_out2, t)

# ì—­ì „íŒŒ
dout = softmaxWithloss.backward()
# dout = relu_out2
print('dout : \n', dout)

# ì€ë‹‰ 2ì¸µ
# relu í†µê³¼
relu_dout = relu2.backward(dout)
print('relu_dout : \n', relu_dout)

# affine í†µê³¼
dout1, dw2, db2 = affine2.backward(relu_dout)
print('dout1 : \n', dout1)

# ì€ë‹‰ 1ì¸µ
relu_dout1 = relu1.backward(dout1)
print('relu_dout1 : \n', relu_dout1)
dx, dw1, db1 = affine1.backward(relu_dout1)
print('dx : \n', dx)



 words">1 min</span> -->


          <!-- page views -->
          

        </div>

      </div> <!-- .post-meta -->

      <div class="post-content">

        

        <p>ì €ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” forwardì™€ backward ê·¸ë¦¬ê³  í™œì„±í™” í•¨ìˆ˜ì¸ Reluí•¨ìˆ˜ë¥¼ í´ë˜ìŠ¤ë¡œ êµ¬í˜„í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” cross entropyì™€ softmaxë„ í•¨ê»˜ êµ¬í˜„í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p>

<h2 id="cross-entropy-ì™€-softmax">cross entropy ì™€ softmax</h2>

<p>ë³´í†µ ì‹ ê²½ë§ì—ì„œ ë¶„ë¥˜í•  ë•Œ, softmaxë¥¼ ì‚¬ìš©í•˜ë©°, softmaxëŠ” ì‹ ê²½ë§ì˜ ì¶œë ¥ì¸µ ë§ˆì§€ë§‰ì—ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤. softmaxì— ê´€í•œ ë” ìì„¸í•œ ì„¤ëª…ì€ <a href="https://kejdev.github.io/2019/11/06/ML-Machine-Learning-activation-function/">ì—¬ê¸°</a>ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. softmaxì™€ í•¨ê»˜ ì˜¤ì°¨ í•¨ìˆ˜ë¡œ cross entropyí•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, cross entropy errorëŠ” ì¤„ì—¬ì„œ CEEë¼ê³ ë„ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.</p>

\[E\quad =-\sum _{ k }{ { t }_{ k } } { log\, y }_{ k }\quad\]

<p>\(y_k\)ëŠ” ì‹ ê²½ë§ì—ì„œ ë‚˜ì˜¤ëŠ” ì¶œë ¥ ê°’ì´ë©° 0ì—ì„œ 1ì‚¬ì´ì˜ ê°’ì´ ë‚˜ì˜µë‹ˆë‹¤. $t_k$ëŠ” ì •ë‹µ ë ˆì´ë¸”ì´ë©°, ì •ë‹µì´ ì•„ë‹Œ ë‚˜ë¨¸ì§€ \(t_k\)ê°€ 0ì´ë©°, \(log\)ëŠ” ë°‘ì´ \(e\)ì¸ ìì—°ë¡œê·¸ì…ë‹ˆë‹¤. cross entropyë¥¼ Pythonìœ¼ë¡œ ì‘ì„±í•  ë•Œ ì•„ì£¼ ì‘ì€ ê°’ì„ ë”í•´ì¤˜ì•¼ í•˜ëŠ”ë°, ê·¸ ì´ìœ ëŠ” yê°€ 0ì¸ ê²½ìš° -infê°’ì„ ì˜ˆë°©í•˜ê¸° ìœ„í•´ì„œ ì…ë‹ˆë‹¤.</p>

<p>íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">crossEntropyError</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">t</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<p>ê·¸ëŸ¬ë‚˜ ìœ„ì™€ ê°™ì´ êµ¬í˜„í•˜ê²Œ ëœë‹¤ë©´, \(y\)ê°€ \(0\)ë˜ë²„ë¦¬ëŠ” ê²½ìš°ì— -infê°’ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•„ì£¼ ì‘ì€ ê°’ì„ ë”í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">crossEntropyError</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-7</span> <span class="c1">#ì•„ì£¼ ì‘ì€ ê°’ (yê°€ 0ì¸ ê²½ìš° -inf ê°’ì„ ì˜ˆë°©)
</span>    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">t</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="o">+</span><span class="n">delta</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<p>ê·¸ë˜ì„œ cross entropyë¥¼ êµ¬í˜„í•  ë•ŒëŠ” ìœ„ì™€ ê°™ì´ ì•„ì£¼ ì‘ì€ ê°’ì„ $y$ì— ë”í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">crossEntropyError</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-7</span> 
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">t</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="o">+</span><span class="n">delta</span><span class="p">))</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="c1"># label = 5
</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s">"-- ì •ë‹µì¸ ê²½ìš° --"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"CEE :"</span><span class="p">,</span> <span class="n">crossEntropyError</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">))</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"-- ì˜¤ë¥˜ì¸ ê²½ìš° --"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"CEE :"</span><span class="p">,</span> <span class="n">crossEntropyError</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<p>softmaxëŠ” ì•„ë˜ì™€ ê°™ì´ íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>  
    <span class="n">exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">sum_exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp_a</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">exp_a</span> <span class="o">/</span> <span class="n">sum_exp_a</span>
    <span class="k">return</span> <span class="n">y</span>
</pre></td></tr></tbody></table></code></div></div>
<h2 id="softmax-with-loss-í´ë˜ìŠ¤-ë§Œë“¤ê¸°">Softmax With loss í´ë˜ìŠ¤ ë§Œë“¤ê¸°</h2>

<p>í´ë˜ìŠ¤ ì´ë¦„ì€ ì›í•˜ëŠ” ê±¸ë¡œ í•˜ì…”ë„ ë˜ì§€ë§Œ, ì €ëŠ” ëª…í™•í•œ êµ¬ë¶„ì„ ìœ„í•´ ì´ë ‡ê²Œ ì§“ê² ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ softmaxì™€ cross entropy í•¨ìˆ˜ ë‘ê°œ ë‹¤ êµ¬í˜„í–ˆê¸° ë•Œë¬¸ì—, ì¶”ê°€ í•  í•¨ìˆ˜ëŠ” ì—†ìœ¼ë©° lossí•¨ìˆ˜ì— ëŒ€í•´ forwardì™€ backwardë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ë§Œ êµ¬í˜„í•˜ë©´ Softmax With loss í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-7</span>  
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">delta</span><span class="p">))</span> <span class="o">/</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>  <span class="c1"># ì¶”ê°€í•œ ë¶€ë¶„
</span>    <span class="n">exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">sum_exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp_a</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">exp_a</span> <span class="o">/</span> <span class="n">sum_exp_a</span>

    <span class="k">return</span> <span class="n">y</span>

<span class="k">class</span> <span class="nc">SoftmaxWithloss</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">t</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">t</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy_error</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>

    <span class="k">return</span> <span class="n">dx</span>
</pre></td></tr></tbody></table></code></div></div>

<p>SoftmaxWithlossí•¨ìˆ˜ ì•ˆì—ì„œ ì‚¬ìš©í•œ forwardì™€ backwardí•¨ìˆ˜ê°€ ì´í•´ê°€ ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ <a href="https://kejdev.github.io/2019/11/29/ML-Machine-Learning-backpropagation/">ì—¬ê¸°</a>ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”. 
ì—¬ê¸°ê¹Œì§€ êµ¬í–ˆë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ 2ì¸µì§œë¦¬ ì‹ ê²½ë§ì„ ì‰½ê²Œ ë§Œë“¤ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-7</span> 
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">delta</span><span class="p">))</span> <span class="o">/</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>  
    <span class="n">exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">sum_exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp_a</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">exp_a</span> <span class="o">/</span> <span class="n">sum_exp_a</span>

    <span class="k">return</span> <span class="n">y</span>


<span class="k">class</span> <span class="nc">Affine</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dW</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">db</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dW</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">db</span>


<span class="k">class</span> <span class="nc">Relu</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># ì„¤ëª… : x ê°’ì´ 0 ì´í•˜ë©´ True í¬ë©´  False; True, False ë¥¼ ê°€ì§€ëŠ” numpy ë°°ì—´
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># ì„¤ëª… : mask ê°€ Ture ì¸ ê³³ì€ x ì˜ ì›ì†Œ ê°’ì´ 0, False ì¸ ê³³ì€ ê·¸ëŒ€ë¡œ ì¶œë ¥
</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dout</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span>
        <span class="k">return</span> <span class="n">dx</span>

<span class="k">class</span> <span class="nc">SoftmaxWithloss</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">t</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">t</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy_error</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>

        <span class="k">return</span> <span class="n">dx</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="c1"># ìˆœì „íŒŒ
</span><span class="n">affine1</span> <span class="o">=</span> <span class="n">Affine</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">)</span>
<span class="n">affine2</span> <span class="o">=</span> <span class="n">Affine</span><span class="p">(</span><span class="n">w2</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
<span class="n">relu1</span> <span class="o">=</span> <span class="n">Relu</span><span class="p">()</span>
<span class="n">relu2</span> <span class="o">=</span> <span class="n">Relu</span><span class="p">()</span>

<span class="c1"># ì€ë‹‰ 1ì¸µ
</span><span class="n">out1</span> <span class="o">=</span> <span class="n">affine1</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">relu_out1</span> <span class="o">=</span> <span class="n">relu1</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>

<span class="c1"># ì€ë‹‰ 2ì¸µ
</span><span class="n">out2</span> <span class="o">=</span> <span class="n">affine2</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">relu_out1</span><span class="p">)</span>
<span class="n">relu_out2</span> <span class="o">=</span> <span class="n">relu2</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'out : </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">relu_out2</span><span class="p">)</span>

<span class="c1"># softmax
</span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">softmaxWithloss</span> <span class="o">=</span> <span class="n">SoftmaxWithloss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">softmaxWithloss</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">relu_out2</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

<span class="c1"># ì—­ì „íŒŒ
</span><span class="n">dout</span> <span class="o">=</span> <span class="n">softmaxWithloss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="c1"># dout = relu_out2
</span><span class="k">print</span><span class="p">(</span><span class="s">'dout : </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>

<span class="c1"># ì€ë‹‰ 2ì¸µ
# relu í†µê³¼
</span><span class="n">relu_dout</span> <span class="o">=</span> <span class="n">relu2</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'relu_dout : </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">relu_dout</span><span class="p">)</span>

<span class="c1"># affine í†µê³¼
</span><span class="n">dout1</span><span class="p">,</span> <span class="n">dw2</span><span class="p">,</span> <span class="n">db2</span> <span class="o">=</span> <span class="n">affine2</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">relu_dout</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'dout1 : </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">dout1</span><span class="p">)</span>

<span class="c1"># ì€ë‹‰ 1ì¸µ
</span><span class="n">relu_dout1</span> <span class="o">=</span> <span class="n">relu1</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'relu_dout1 : </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">relu_dout1</span><span class="p">)</span>
<span class="n">dx</span><span class="p">,</span> <span class="n">dw1</span><span class="p">,</span> <span class="n">db1</span> <span class="o">=</span> <span class="n">affine1</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">relu_dout1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'dx : </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">dx</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets//images/softmax.png" /></p>


      </div>

      <div class="post-tail-wrapper text-muted">

        <!-- categories -->
        <!-- 
        <div class="post-meta mb-3">
          <i class="far fa-folder-open fa-fw mr-1"></i>
          
            <a href='/categories/machine-learning/'>Machine Learning</a>,
            <a href='/categories/ml/'>ML</a>
        </div>
         -->

        <!-- tags -->
        <!--  -->

        <div class="post-tail-bottom
          d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
          
          <div class="license-wrapper">
            This post is licensed under
            <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>
            by the author.
          </div>
          

          <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=íŒŒì´ì¬ í´ë˜ìŠ¤ë¡œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°(cross_entropy, softmax, Softmax With loss ) - ğŸ— ì–‘ë…ì¹˜í‚¨ ğŸ—&url=http://localhost:4000/posts/ml-class-softmax/" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=íŒŒì´ì¬ í´ë˜ìŠ¤ë¡œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°(cross_entropy, softmax, Softmax With loss ) - ğŸ— ì–‘ë…ì¹˜í‚¨ ğŸ—&u=http://localhost:4000/posts/ml-class-softmax/" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://telegram.me/share?text=íŒŒì´ì¬ í´ë˜ìŠ¤ë¡œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°(cross_entropy, softmax, Softmax With loss ) - ğŸ— ì–‘ë…ì¹˜í‚¨ ğŸ—&url=http://localhost:4000/posts/ml-class-softmax/" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    
      
        <a href="https://www.linkedin.com/sharing/share-offsite/?url=http://localhost:4000/posts/ml-class-softmax/" data-toggle="tooltip" data-placement="top"
          title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin">
          <i class="fa-fw fab fa-linkedin"></i>
        </a>
    

    <i class="fa-fw fas fa-link small" onclick="copyLink()"
        data-toggle="tooltip" data-placement="top" title="Copy link"></i>

  </span>
</div>


        </div><!-- .post-tail-bottom -->

      </div>

    </div> <!-- .post -->


  </div> <!-- #post-wrapper -->

  

  

  <!--
  The Pannel on right side (Desktop views)
-->


</div> <!-- .row -->

<div class="row">
  <div class="col-12 col-lg-11 col-xl-8" 
    style="margin:0 auto; margin-top:25px; max-width: 850px; padding:0px 30px">
    <div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">

    <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->




    <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/posts/ML-relu-class-2layer/" class="btn btn-outline-primary"
    prompt="Older">
    <p>íŒŒì´ì¬ í´ë˜ìŠ¤ë¡œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°(relu,forward,backward)</p>
  </a>
  

  
  <a href="/posts/ml-Batch-Nomalization/" class="btn btn-outline-primary"
    prompt="Newer">
    <p>Batch Nomalization í•™ìŠµ ì‹¤ì œ ì‚¬ìš©í• ë•Œ ì£¼ì˜ í•  ì </p>
  </a>
  

</div>


    <!--  -->

    </div>

  </div> <!-- .col-* -->

</div> <!-- .row -->


  <!--
  image lazy load: https://github.com/ApoorvSaxena/lozad.js
-->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script>

<script type="text/javascript">
  const imgs = document.querySelectorAll('.post-content img');
  const observer = lozad(imgs);
  observer.observe();
</script>




        <!--
  The Footer
-->

<footer class="d-flex w-100 justify-content-center">
  <div class="d-flex justify-content-between align-items-center">
    <div class="footer-left">
      <p class="mb-0">
        Â© 2022
        <a href="https://www.instagram.com/ao_ej125">kejdev</a>.
        
        <span data-toggle="tooltip" data-placement="top"
          title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
        
      </p>
    </div>

    <div class="footer-right">
      <p class="mb-0">
        Powered by
        <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
        with
        <a href="https://github.com/cotes2020/jekyll-theme-chirpy"
          target="_blank" rel="noopener">Chirpy</a>
        theme.
      </p>
    </div>

  </div> <!-- div.d-flex -->
</footer>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-xl-11 post-content">
    <div id="search-hints">
      <h4 class="text-muted mb-4">Trending Tags</h4>

      















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        



      
        
        <a class="post-tag" href="/tags/python/">Python</a>
      
        
        <a class="post-tag" href="/tags/%EB%AC%B8%EB%B2%95/">ë¬¸ë²•</a>
      
        
        <a class="post-tag" href="/tags/%ED%86%B5%EA%B3%84/">í†µê³„</a>
      
        
        <a class="post-tag" href="/tags/ml/">ML</a>
      
        
        <a class="post-tag" href="/tags/r/">R</a>
      
        
        <a class="post-tag" href="/tags/%EB%85%BC%EB%AC%B8/">ë…¼ë¬¸</a>
      
        
        <a class="post-tag" href="/tags/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">ì•Œê³ ë¦¬ì¦˜</a>
      
        
        <a class="post-tag" href="/tags/db/">DB</a>
      
        
        <a class="post-tag" href="/tags/go/">GO</a>
      
        
        <a class="post-tag" href="/tags/oracle/">Oracle</a>
      

    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    
      <!--
  mermaid-js loader
-->

<script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script>
<script>
  $(function() {
    let initTheme = "default";

    if ($("html[mode=dark]").length > 0
      || ($("html[mode]").length == 0
        && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) {
      initTheme = "dark";
    }

    let mermaidConf = {
      theme: initTheme  /* <default|dark|forest|neutral> */
    };

    /* Markdown converts to HTML */
    $("pre").has("code.language-mermaid").each(function() {
      let svgCode = $(this).children().html();
      $(this).addClass("unloaded");
      $(this).after(`<div class=\"mermaid\">${svgCode}</div>`);
    });

    mermaid.initialize(mermaidConf);
  });
</script>

    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    <!--
  Jekyll Simple Search loader
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="http://localhost:4000{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    <div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div>    <div><i class="fa fa-tag fa-fw"></i>{tags}</div>  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No result founds.</p>'
});
</script>


  </body>

</html>

