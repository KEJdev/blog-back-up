<!DOCTYPE html>



<html lang="en" 
  
    mode="light"
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  
    <meta name="pv-cache-enabled" content="false">

    
  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="🍗 양념치킨 🍗" />
<meta name="author" content="KEJdev" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/page10/" />
<meta property="og:url" content="http://localhost:4000/page10/" />
<meta property="og:site_name" content="🍗 양념치킨 🍗" />
<meta property="og:type" content="website" />
<link rel="prev" href="http://localhost:4000/page9" />
<link rel="next" href="http://localhost:4000/page11" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="🍗 양념치킨 🍗" />
<meta name="google-site-verification" content="google_meta_tag_verification" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"KEJdev"},"headline":"🍗 양념치킨 🍗","url":"http://localhost:4000/page10/"}</script>
<!-- End Jekyll SEO tag -->


  <title>🍗 양념치킨 🍗
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://www.favicon-generator.org/
-->



<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">
<link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">

<!-- <link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png">
<link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"> -->
<!-- <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png">

<link rel="icon" type="image/png" sizes="192x192"  href="/assets/img/favicons/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"> -->

<link rel="manifest" href="/assets/img/favicons/manifest.json">
<meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'> 
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="/assets/img/favicons/favicon.png">
<meta name="theme-color" content="#ffffff">


  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com">

  <!-- GA -->
  

  <!-- jsDelivr CDN -->
  <link rel="preconnect" href="cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="cdn.jsdelivr.net">

  <!-- Bootstrap -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
    integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous">

  <!-- Font Awesome -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"
    integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ="
    crossorigin="anonymous">

  <!--
  CSS selector for site.
-->

<link rel="stylesheet" href="/assets/css/style.css">




  <!-- JavaScripts -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

  <script defer
    src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script>

  <!--
  JS selector for site.
-->


  





<script defer src="/assets/js/dist/home.min.js"></script>






</head>


  <body data-spy="scroll" data-target="#toc">

    <!--
  The Side Bar
-->

<div id="sidebar" style="width:190px" class="d-flex flex-column align-items-end">

  <div class="profile-wrapper text-center">
    <div style="display:flex">
      <div id="avatar" style="margin:0 auto 0 auto;">
        <a href="/" alt="avatar" class="mx-auto">
          
          <img style="max-width:100%;" src="/assets/img/favicons/mycat.jpg" alt="avatar" onerror="this.style.display='none'">
        </a>
      </div>
    </div>

    <div style="display:flex">
      <div style="margin:0 auto 0 auto; font-weight:550px;" >
        <a href="/">🍗 양념치킨 🍗</a>
      </div>
    </div>

    <div style="display:flex">
      <div class="site-subtitle font-italic"  style="margin:0 auto 0 auto;">고양이 좋아하는 개발자</div>
    </div>
  </div><!-- .profile-wrapper -->

  <ul class="w-100">
    <!-- home -->
    <li class="nav-item active">
      <a href="/" class="nav-link">
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/tabs/categories/" class="nav-link">
        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tabs/archives/" class="nav-link">
        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tabs/about/" class="nav-link">
        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center">

    


  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <div id="main-wrapper">
      <div id="main">

        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->


<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->


<!-- Add attribute 'hide-bullet' to the checkbox list -->




<!-- return -->
<div class="row">
  <div class="col-12 col-lg-11 col-xl-8" style="margin:0 auto; max-width: 750px">
    <div id="page" class="post pb-5 pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4 mb-md-4">
    
      



<!-- Get pinned posts -->







<!-- Get default posts -->











<div id="post-list">



  <div class="post-preview">
    <h1>
      <a href="/posts/go-for/">Go 반복문-for문</a>
    </h1>

    <div class="post-content">
      <p>
        





        오늘은 GO 반복문과 조건문에 대해 배워보도록 하겠습니다. 예전 포스팅에서 한번 언급 하긴 했었는데 GO에서 반복문은 for문 밖에 없다고 이야기 했었습니다. 오늘은 그 for문에 대해 알아보도록 하겠습니다. Go가 설치되어 있지 않지만 실행을 해보고 싶다면, 여기를 클릭해주세요.

Go 반복문(for문)

Go 언어는 반복문이 for문 밖에 없으며 ...
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Tue, Feb  4, 2020,  2:00 PM +0800"
  >

  
  

  
    Feb  4, 2020
  

  <i class="unloaded">2020-02-04T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="오늘은 GO 반복문과 조건문에 대해 배워보도록 하겠습니다. 예전 포스팅에서 한번 언급 하긴 했었는데 GO에서 반복문은 for문 밖에 없다고 이야기 했었습니다. 오늘은 그 for문에 대해 알아보도록 하겠습니다. Go가 설치되어 있지 않지만 실행을 해보고 싶다면, 여기를 클릭해주세요.

Go 반복문(for문)

Go 언어는 반복문이 for문 밖에 없으며 기본적인 for반복문은 c와 java와 거의 유사합니다. 다른점이 있다면 소괄호가 필요하지 않다는 점뿐입니다. 하지만 실행문을 위한 중괄호 {}는 필요합니다.

1
2
3
4
5
6
7
8
9
10
11
package main

import "fmt"

func main(){
    sum := 0
    for i := 0; i&lt;=10; i++{
        sum += i
    }
    fmt.Println(sum)
}


for문을 사용하여 1부터 10까지 더하는 함수 하나를 만들어보면 위와 같이 만들 수 있습니다. c와 java의 for문과 별다른 차이가 없기 때문에 사실 어렵지는 않지만 혹시 모르니 주석을 달아 설명을 하자면 아래와 같습니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
package main

import "fmt"

func main(){
    //sum 이라는 변수 생성 
    sum := 0

    // for문 시작
    // 처음에 i는 0이라고 지정
    // i가 10이 될때까지 반복문이 돌아감
    for i := 0; i&lt;=10; i++{
        sum += i
        // sum 이라는 변수에 계속 i를 더함 1+2+3+4+...
    }
    fmt.Println(sum)
}


또한 C와 java처럼 향상된 for문을 사용할 수 있습니다.

1
2
3
4
5
6
7
8
9
10
11
package main

import "fmt"

func main() {
	sum := 1
	for sum &lt; 1000 {
		sum += sum
	}
	fmt.Println(sum)
}

 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



  <div class="post-preview">
    <h1>
      <a href="/posts/ml-tensorflow-session/">텐서플로우 사용하기, Hello, Tensorflow! (실행 구조와 구구단 출력)</a>
    </h1>

    <div class="post-content">
      <p>
        





        언어를 새로 배우거나 무언가를 새로 배울 때, 우리는 가장 먼저 Hello, world! 를 가장 먼저 찍어냅니다. Tensorflow 을 포스팅 하는 기념으로 Hello, Tensorflow!를 찍어보겠습니다.

Tensorflow 기본 구조

우선 텐서플로우가 설치가 안되어 있다면 아래와 같이 설치 해주세요.

pip install tensorfl...
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Mon, Feb  3, 2020,  2:00 PM +0800"
  >

  
  

  
    Feb  3, 2020
  

  <i class="unloaded">2020-02-03T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="언어를 새로 배우거나 무언가를 새로 배울 때, 우리는 가장 먼저 Hello, world! 를 가장 먼저 찍어냅니다. Tensorflow 을 포스팅 하는 기념으로 Hello, Tensorflow!를 찍어보겠습니다.

Tensorflow 기본 구조

우선 텐서플로우가 설치가 안되어 있다면 아래와 같이 설치 해주세요.

1
pip install tensorflow 


설치가 되었다면 모듈을 가져와서 tf를 호출합니다.

1
import tensorflow as tf 


그리고 그래프를 실행할 세션을 구성합니다. (참고로 포스팅에서 사용하는 tf는 1.x 버전입니다.)

1
2
3
4
5
6
7
8
sess=tf.Session()                        # 그래프를 실행할 세션을 구성한다. 
hello=tf.constant('Hello, Tensorflow')  

# # # # # # # # 모델을 구성하는 부분 ↑
# # # # # # # # 모델을 실행하는 부분 ↓ 

print(sess.run(hello))
print(str(sess.run(hello),encoding="utf-8"))


위에서 변수를 정의 햇으나 실행은 정의한 시점에서 실행되는 것이 아니고 Session 객체와 run 메소드를 사용할 때 계산되어 실행됩니다.

이번에는 간단하게 덧셈을 출력해보겠습니다.

1
2
3
4
5
6
7
8
9
import tensorflow as tf 
x=tf.constant(35, name='x')              # x라는 상수값을 만들어 숫자 35 지정
y=tf.Variable(x+5, name='y')            # y라는 변수를 만들고 방정식 x+5로 정의

model=tf.global_variables_initializer() # 변수 초기화

with tf.Session() as sess:               # 값을 계산하기 위한 세션 생성 (세션 열기)
    sess.run(model)                     # 위에서 초기화한 model을 실행하겠다.
    print(sess.run(y))                    # 변수 y를 실행하며 현재값 출력


월래는 세션을 연 뒤에는 닫아야는데 with절 후에는 자동으로 닫히기 때문에 그냥 출력합니다. 또한 텐서플로우는 빌딩 구조와 실행구조(session)가 분리되어 있습니다.

1
2
3
4
5
6
7
8
9
10
11
# 빌딩 과정
import tensorflow as tf  
x2 = tf.linspace(-1.0, 1.0,10) # -1 ~ 1 사이의 숫자 중 10개를 랜덤으로 출력 

g=tf.get_default_graph()
print([op.name for op in g.get_operations()])

# 실행 과정
sess=tf.Session()
print(sess.run(x2))
sess.close()


Tensorflow 실행 구조

Tensorflow Session은 fetch와 feed 2가지 방법으로 처리 할 수 있습니다.



fetch는 Tensor에 할당 되어야 실제 Session에서 실행을 할 수 있습니다.


  한개 실행할 때


1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
import tensorflow as tf

a=tf.constant(1)
b=tf.constant(2)
c=tf.add(a,b)

sess=tf.Session()
print(sess.run(c))
sess.close()


# 또는

import tensorflow as tf

with tf.Session() as sess:
    print(tf.add(1,2).eval())



  여러 개 실행할 때


1
2
3
4
5
6
7
8
9
10
11
12
13
14
import tensorflow as tf

input1=tf.constant(3.0)
input2=tf.constant(2.0)
input3=tf.constant(5.0)

# fetch 여러 개 되는 부분

intermed=tf.add(input2,input3)
mul=tf.multiply(input1,input3)

with tf.Session() as sess:
    result=sess.run([mul,intermed])
    print(result)


feed 같은 경우는 Session에서 반드시 feed_dict로 처리 값을 할당해주어야 합니다.

1
2
3
4
5
6
7
8
9
10
11
12
import tensorflow as tf

a=tf.placeholder("float")
b=tf.placeholder("float")

y=tf.multiply(a,b)
z=tf.add(y,y)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(y,feed_dict={a:3, b:3}))
    print(sess.run(z,feed_dict={a:4, b:4}))


그래서 응용하여 구구단을 출력해보자면 아래와 같이 작성 할 수 있습니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
import tensorflow as tf

## 구조(그래프) 선언부
x = tf.Variable(0, name='x')     
# tensorboard 로 그래프를 그리기 위해서는 name 을 지정해 줘야한다.

y = tf.Variable(0, name='y')     
# name 을 지정할 때 이름이 중복되면 안되고, 중복 사용을 위해서는 
z = tf.multiply(x, y, name='z')  
# 다른 옵션을 사용해야 한다.

model = tf.global_variables_initializer()  # 변수(노드)를 위치 및 생성
merged = tf.summary.merge_all()  # 그래프를 그리는데 사용될 변수(노드)를 취합

## 선언한 구조(그래프) 실행부
with tf.Session() as sess:  # 세션(하나의 사용자) 생성
    sess.run(model)  # 위에서 생성한 그래프 구조를 실행
    for i in range(2, 10):
        for j in range(1, 10):
            print(i, ' x ', j, ' = ',sess.run(z,feed_dict={x:i, y:j}))  
            # 초기화된 변수에 값을 feed
            writer = tf.summary.FileWriter('./logs', sess.graph)
            # tensorboard 그래프를 그리는데 사용할 실행 로그를 저장할 폴더 지정

 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



  <div class="post-preview">
    <h1>
      <a href="/posts/ml-tensorflow/">텐서플로우란?</a>
    </h1>

    <div class="post-content">
      <p>
        





        머신러닝 개발자들이 많이 사용하는 Tensorflow에 대해서 간단하게 알아보겠습니다.
요즘에는 텐서플로우외에도 케라스나 파이토치등 다양하지만 저는 아직 텐서플로우가 편해서 텐서플로우를 쓰고 있습니다. 맨 처음 머신러닝을 접할 때, 텐서플로우로 접했기 때문인거 같습니다.

같이 공부했던 사람들 중 케라스나 파이토치로 시작한 사람들이 꽤 있었는데 케라스...
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Sun, Feb  2, 2020,  2:00 PM +0800"
  >

  
  

  
    Feb  2, 2020
  

  <i class="unloaded">2020-02-02T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="머신러닝 개발자들이 많이 사용하는 Tensorflow에 대해서 간단하게 알아보겠습니다.
요즘에는 텐서플로우외에도 케라스나 파이토치등 다양하지만 저는 아직 텐서플로우가 편해서 텐서플로우를 쓰고 있습니다. 맨 처음 머신러닝을 접할 때, 텐서플로우로 접했기 때문인거 같습니다.

같이 공부했던 사람들 중 케라스나 파이토치로 시작한 사람들이 꽤 있었는데 케라스나 파이토치로 시작한 사람들은 텐서플로우가 조금 더 어렵다고 하더라구요. 그래서 커뮤니티 사이에서 가끔 텐서플로우로 먼저 시작하라는 글이 보이기도 하더라구요.

이 글 쓴 시점에서는 현재 텐서플로우는 2.0이 나와 있는 상황입니다. 2.0버전이랑 1.x 버전이랑은 문법 차이가 꽤 나기도 하고, 성능 차이도 있다고 합니다. 지금은 1.x 버전에 관하여 포스팅 하고는 있지만 조만간 2.0에 대해서도 포스팅을 해야겠네요.

Tensorflow

텐서플로우는 딥러닝을 위해 구글에서 만든 오픈소스 라이브러리입니다. 간단하게 Tensorflow의 특징을 살펴보면 2가지 정도 있다고 보면 됩니다.


  Tensorflow 특징


1) 데이터 플로우 그래프를 통한 풍부한 표현력



데이터 플로우 그래프(Data Flow Graph)방식을 사용하며, 그래프를 시작하기 위해서 텐서보드라는 것을 사용할 수 있습니다.

2) 코드 수정 없이 CPU/GPU 모드 동작

특별한 코드 수정 없이 CPU나 GPU를 사용하여 학습을 시킬 수 있습니다.

Tensorflow 용어

사실 특별히 용어라고 할 것까지는 없지만 한번 정리를 해보자면, 아래와 같은 용어가 있습니다.


  
    
      용어
       설명 
    
  
  
    
      오퍼레이션 (Operation)
      그래프 상의 노드는 오퍼레이션(OP)로 불린다. 오퍼레이션은 하나 이상의 텐서를 받을 수 있으며, 계산을 수행하고, 결과를 하나 이상의 텐서로 반환할 수 있다.
    
    
      텐서 (Tensor)
      내부적으로 모든 데이터는 텐서를 통해 표현된다. 텐서는 일종의 다차원 배열인데, 그래프 내의 오퍼레이션 간에 텐서가 전달된다.
    
    
      세션 (Session)
      그래프를 실행하기 위해서는 세션 객체가 필요하다. 세션은 오퍼레이션의 실행 환경을 캡슐화 한것이다.
    
    
      변수 (Variables)
      그래프 실행 시 파라미터를 저장하고 갱신하는데 사용한다. 메모리상에서 텐서를 저장하는 버퍼 역활을 한다.
    
  


Tensorflow 설치

Tensorflow 설치는 간단하며, 아래와 같다.


  
    Anaconda 환경
pip install tensorflow
  
  
    파이참 환경
file → setting → project interpreter
  


 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



  <div class="post-preview">
    <h1>
      <a href="/posts/ml-dropout-overfitting/">오버피팅 억제를 위한 방법! Dropout!</a>
    </h1>

    <div class="post-content">
      <p>
        





        오버피팅을 억제하기 위한 방법으로 Dropout에 대해 알아보도록 하겠습니다. 오버피팅은 학습을 시키면서 흔히 접할 수 있는 문제이며, 풀어야 할 문제 중 하나 입니다. 오늘은 이러한 오버피팅에 대한 문제를 바로 잡을 수 있는 방법 중 가장 간단한 방법에 대해 알아보겠습니다.

Dropout

Dropout은 오버피팅을 억제하기 위해 뉴런을 임의로 삭...
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Sat, Feb  1, 2020,  2:00 PM +0800"
  >

  
  

  
    Feb  1, 2020
  

  <i class="unloaded">2020-02-01T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="오버피팅을 억제하기 위한 방법으로 Dropout에 대해 알아보도록 하겠습니다. 오버피팅은 학습을 시키면서 흔히 접할 수 있는 문제이며, 풀어야 할 문제 중 하나 입니다. 오늘은 이러한 오버피팅에 대한 문제를 바로 잡을 수 있는 방법 중 가장 간단한 방법에 대해 알아보겠습니다.

Dropout

Dropout은 오버피팅을 억제하기 위해 뉴런을 임의로 삭제하면서 학습하는 방법입니다.



신경망 전체를 학습시키지 않고 일부 노드만 무작위로 골라 학습 시키는 방법입니다. 학습하는 중간중간 일정 비율로 노드들을 무작위로 골라 출력을 0으로 만들어 신경망의 출력을 계산하는 방법입니다. Dropout을 적용하면 학습되는 노드와 가중치들이 매번 달라지기 때문에 신경망이 과적합에 빠지는 것을 예방할 수 있습니다.

Dropout의 개념을 쉬운 예를 들어서 애기하면, 전문가가 많으면 오히려 오답이 나올 수 있으며, 사공이 많으면 배가 산으로 간다. 라는 속담을 생각하면 조금 더 쉽게 이해 할 수 있습니다.

여기서 사공이 많으면 배가 산으로 가기 때문에 몇 명의 전문가만 선별하여 반복적으로 같은 결과가 나오면 그것을 답으로 선택하겠다. 라고 하는 것이 앙상블이라고 하는 학습 방법이 있는데, Dropout과 자주 사용 되는 학습 방식입니다.



예를 들어 위와 같은 결과를 내는 신경망이 있다고 할 때, 드롭아웃(Dropout)을 적용하게 되면 아래 그림과 같을 수 있습니다.



Dropout은 신호를 보내지 않기 때문에 이런 결과를 얻을 수 있습니다.


 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



  <div class="post-preview">
    <h1>
      <a href="/posts/ml-Batch-Nomalization/">Batch Nomalization 학습 실제 사용할때 주의 할 점</a>
    </h1>

    <div class="post-content">
      <p>
        





        오늘은 Batch Nomalization 학습 실제 사용할때 주의 할 점과 가중치 초기화의 중요성에 대해 같이 보도록 하겠습니다.

가중치 초기화의 중요성

가중치 초기값을 적절하게 설정하면 각 층의 활성화 값의 분포가 적당히 퍼지는 효과가 발생합니다. 그리고 활성화 값이 적절하게 분포하게 되면 학습이 잘되고 정확도가 높아집니다.

아래의 그림은 학습...
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Sat, Feb  1, 2020,  2:00 PM +0800"
  >

  
  

  
    Feb  1, 2020
  

  <i class="unloaded">2020-02-01T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="오늘은 Batch Nomalization 학습 실제 사용할때 주의 할 점과 가중치 초기화의 중요성에 대해 같이 보도록 하겠습니다.

가중치 초기화의 중요성

가중치 초기값을 적절하게 설정하면 각 층의 활성화 값의 분포가 적당히 퍼지는 효과가 발생합니다. 그리고 활성화 값이 적절하게 분포하게 되면 학습이 잘되고 정확도가 높아집니다.

아래의 그림은 학습이 잘 안되는 가중치 분포의 예입니다.



아래의 그림은 학습이 잘된 경우입니다.



한 눈에 봐도 고르게 잘 된것을 알 수 있습니다.

가중치 초기값 선정하는 5가지 방법

가중치 초기값을 선정하는 방법에는 대략 5가지 정도가 있습니다.

1. 가중치 초기값을 0으로 선정.

이 방법은 추천하지 않습니다. 왜냐하면 학습이 잘되지 않기 때문이죠.
하지만 이런 방법도 예전에 있는 있었다. 로 넘어가시면 될 것 같습니다.

2. 표준편차가 1인 정규분포를 사용해 초기값 선정.

표준편차가 클수룩 Data가 더 많이 흩어져 있습니다. 
ex) 시험문제가 어려우면 아주 잘하는 학생들과 아주 못하는 학생들로 점수가 딱 나눠진다.

1
1 * np.random.randm(10,100)




3. 표준편차가 0.01인 정규분포를 사용해 초기값 선정.

표준편차가 작을수록 Data가 평균에 가깝게 분포합니다. 
ex) 시험문제가 쉬우면 학생들 점수가 평균에 가깝다.

1
0.01 * np.random.randm(10,100)




4.Xavier 초기값 선정.

표준편차가 \(√(1/n)\)인 (n은 앞층의 노드 수) 정규분포로 초기화하는 방법이 있으며 sigmoid 함수와 짝궁이며 같이 사용됩니다.



5.He 초기값 선정.

표준편차 \(√(2/n)\)인 정규분포로 초기화하는 방법이 있습니다. He는 Relu함수와 짝궁으로 같이 사용됩니다.

배치 정규화

앞에서 가중치 초기값을 적절하게 설정하면 각 층의 활성화 값이 적절하게 분포하여 학습이 잘되고 정확도가 높아지는 것 또한 알 수 있었습니다.

그러나 가중치 초기화를 하더라도 가중치 값이 불규칙하게 분포할 가능성이 있습니다. 여기서 배치 정규화의 개념을 툭 튀어나오게 됩니다. 배치 정규화는 바로 각 층에서 활성화 값이 적당하게 분포 되도록 강제로 조정하게 합니다.

여기서 가장 중요한 사실은 Training data 전체에 대해 mean과 variance를 구하는 것이 아니라, mini batch 단위로 접근하여 계산합니다. 현재 택한 mini batch 안에서만 mean과 variance를 구해서 이 값을 이용해서 mormalize 합니다.

즉, 학습 시 미니배치를 단위로 정구화를 하며, 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화 합니다.

\[{ \mu  }_{ B }\quad \leftarrow \frac { 1 }{ m } \sum _{ i=1 }^{ m }{ x_{ i } }\]

평균

\[{ \sigma  }^{ 2 }_{ B }\quad \leftarrow \frac { 1 }{ m } \sum _{ i=1 }^{ m }{ (x_{ i }- } { \mu  }_{ B })^{ { 2 } }\]

분산

\[{ \hat { x }  }_{ i }\leftarrow \frac { { x }_{ i }-\mu _{ { B } } }{ \sqrt { { \sigma  }_{ B }^{ 2 } } +E  }\]

실제 값 - 평균 , 표준편차 + E

왜 층마다 배치 정규화 작업을 해야 할까요?
그 이유는 신경망은 파라미터(매개변수)가 많기 때문에 학습이 어렵습니다. 특히나 딥러닝 같은 경우는 레이어가 많은데 이 뜻은 가중치가 층마다 다르다 라고 해석 할 수 있습니다. 더욱이 층을 통과할수록 각기 다른 가중치가 쌓이며 가중치의 작은 변화가 가중 되어서 쌓이면 레이어가 많아 질수록 출력되는 값의 변화가 크기 때문입니다.



즉, 가중치 때문에 입력값에 대한 완전히 다른 출력값이 나옴을 알 수 있습니다.

이러한 이유로 배치 정규화가 등장했으며, 배치 정규화는 입력값이 활성화 함수를 통과하기 전에 가중의 변화를 줄이는 것이 목표입니다. 가중의 합이 배치 정규화에 들어오게 되면 기존 값의 스케일을 정규분포로 조정하게 되며 선형이 아닌 비선형 사이로 분포를 유지하여 데이터의 폭(scale), 분포(shift)의 위치를 조절하기 위해 감마(분산)과 베타(평균)을 적용하여 이를 학습하면서 층을 거치게 됩니다.

Batch Normalization 을 사용할 때의 주의할 점.

배치 정규화를 하는 이유는 학습을 하기 위해서 라고 했습니다. 훈련 데이터를 통해서 이미 감마(분산)값과 베타(평균)값이 이미 최적에 맞춰진 상황입니다. 이 모델을 이용하여 테스트를 수행하려고 할 경우 훈련 데이터의 평군, 표준편차 값과 테스트 데이터의 평균, 표준편차 데이터가 다르기 때문에 제대로 테스트 되지 않을 수 있습니다.

즉, 훈련 데이터의 최적의 감마, 베타 값을 가지고 테스트를 하면 값이 제대로 나올 수 있기 때문에 테스트 데이터로 모델을 돌릴 때에는 배치 정규화를 사용하면 안됩니다.

학습 단계에서는 데이터 단위가 배치 단위로 들어오기 때문에 배치의 평균, 분산을 구하는 것이 가능하지만 테스트 단계에서는 배치 단위로 평균/분산을 구하기 어렵습니다. 이를 해결하기 위해서는 두가지 방법이 있습니다.

1. 학습 단계에서 배치 단위의 평균/ 분산을 저장. (이동평균)
2. 테스트시에는 구해진 이동평균을 사용하여 정규화.

Training Data로 학습을 시킬 때는 현재 보고 있는 mini batch에서 평균과 표준 편차를 구하지만, Test Data를 사용하여 
Inference를 할 때는 다소 다른 방법을 사용합니다. mini batch의 값들을 이용하는 대신 지금까지 본 전체 데이터를 다 사용한다는 느낌으로, Training할 때 현재까지 본 Input들의 이동평균 및 비편향추정량의 이동평균을 계산하여 저장해놓은 뒤 이 값으로 normalize를 합니다. 마지막에 감마와 베타를 이용하여 scale/shift 해주는 것은 동일합니다.
 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



  <div class="post-preview">
    <h1>
      <a href="/posts/ml-class-softmax/">파이썬 클래스로 신경망 구현하기(cross_entropy, softmax, Softmax With loss )</a>
    </h1>

    <div class="post-content">
      <p>
        





        저번 포스팅에서는 forward와 backward 그리고 활성화 함수인 Relu함수를 클래스로 구현해보았습니다. 이번에는 cross entropy와 softmax도 함께 구현해보도록 하겠습니다.

cross entropy 와 softmax

보통 신경망에서 분류할 때, softmax를 사용하며, softmax는 신경망의 출력층 마지막에서 사용합니다. ...
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Sat, Jan 18, 2020,  2:00 PM +0800"
  >

  
  

  
    Jan 18, 2020
  

  <i class="unloaded">2020-01-18T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="저번 포스팅에서는 forward와 backward 그리고 활성화 함수인 Relu함수를 클래스로 구현해보았습니다. 이번에는 cross entropy와 softmax도 함께 구현해보도록 하겠습니다.

cross entropy 와 softmax

보통 신경망에서 분류할 때, softmax를 사용하며, softmax는 신경망의 출력층 마지막에서 사용합니다. softmax에 관한 더 자세한 설명은 여기서 확인하실 수 있습니다. softmax와 함께 오차 함수로 cross entropy함수를 사용하는데, cross entropy error는 줄여서 CEE라고도 쓸 수 있습니다. 식은 아래와 같습니다.

\[E\quad =-\sum _{ k }{ { t }_{ k } } { log\, y }_{ k }\quad\]

\(y_k\)는 신경망에서 나오는 출력 값이며 0에서 1사이의 값이 나옵니다. $t_k$는 정답 레이블이며, 정답이 아닌 나머지 \(t_k\)가 0이며, \(log\)는 밑이 \(e\)인 자연로그입니다. cross entropy를 Python으로 작성할 때 아주 작은 값을 더해줘야 하는데, 그 이유는 y가 0인 경우 -inf값을 예방하기 위해서 입니다.

파이썬으로 구현하면 아래와 같이 구현할 수 있습니다.

1
2
3
4
import numpy as np

def crossEntropyError(y, t):
    return -np.sum(t*np.log(y))


그러나 위와 같이 구현하게 된다면, \(y\)가 \(0\)되버리는 경우에 -inf값이 나올 수 있으므로 아주 작은 값을 더해줘야 합니다.

1
2
3
4
5
import numpy as np

def crossEntropyError(y, t):
    delta = 1e-7 #아주 작은 값 (y가 0인 경우 -inf 값을 예방)
    return -np.sum(t*np.log(y+delta))


그래서 cross entropy를 구현할 때는 위와 같이 아주 작은 값을 $y$에 더해줘야 합니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
import numpy as np

def crossEntropyError(y, t):
    delta = 1e-7 
    return -np.sum(t*np.log(y+delta))

t = np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]) # label = 5
y = np.array([0.1, 0.03, 0.05, 0.2, 0.9, 0.0, 0.1, 0.2, 0.12, 0.03])

print("-- 정답인 경우 --")
print("CEE :", crossEntropyError(y, t))

y = np.array([0.1, 0.03, 0.05, 0.2, 0.0, 0.1, 0.2, 0.12, 0.03, 0.9])
print("-- 오류인 경우 --")
print("CEE :", crossEntropyError(y, t))


softmax는 아래와 같이 파이썬으로 구현할 수 있습니다.

1
2
3
4
5
6
def softmax(a):
    c = np.max(a)  
    exp_a = np.exp(a)
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y

Softmax With loss 클래스 만들기

클래스 이름은 원하는 걸로 하셔도 되지만, 저는 명확한 구분을 위해 이렇게 짓겠습니다. 위에서 softmax와 cross entropy 함수 두개 다 구현했기 때문에, 추가 할 함수는 없으며 loss함수에 대해 forward와 backward를 사용하여 클래스만 구현하면 Softmax With loss 클래스를 만들 수 있습니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
import numpy as np

def cross_entropy_error(y, t):
    delta = 1e-7  
    return -np.sum(t * np.log(y + delta)) / y.shape[0]

def softmax(a):
    c = np.max(a)  # 추가한 부분
    exp_a = np.exp(a)
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a

    return y

class SoftmaxWithloss:
    def __init__(self):
        self.loss = None
        self.y = None
        self.t = None

    def forward(self, x, t):
        self.t = t
        self.y = softmax(x)
        self.loss = cross_entropy_error(self.y, self.t)

        return self.loss

    def backward(self, dout=1):
        batch_size = self.t.shape[0]
        dx = (self.y - self.t) / batch_size

    return dx


SoftmaxWithloss함수 안에서 사용한 forward와 backward함수가 이해가 되지 않는다면 여기를 참고해주세요. 
여기까지 구했다면 아래와 같이 2층짜리 신경망을 쉽게 만들어볼 수 있습니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
import numpy as np

def cross_entropy_error(y, t):
    delta = 1e-7 
    return -np.sum(t * np.log(y + delta)) / y.shape[0]

def softmax(a):
    c = np.max(a)  
    exp_a = np.exp(a)
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a

    return y


class Affine:
    def __init__(self, W, b):
        self.W = W
        self.b = b
        self.x = None
        self.dW = None
        self.db = None

    def forward(self, x):
        self.x = x
        out = np.dot(x, self.W) + self.b

        return out

    def backward(self, dout):
        dx = np.dot(dout, self.W.T)
        self.dW = np.dot(self.x.T, dout)
        self.db = np.sum(dout, axis=0)

        return dx, self.dW, self.db


class Relu:
    def __init__(self):
        self.mask = None

    def forward(self, x):
        self.mask = (x &lt;= 0)  # 설명 : x 값이 0 이하면 True 크면  False; True, False 를 가지는 numpy 배열
        out = x.copy()
        out[self.mask] = 0  # 설명 : mask 가 Ture 인 곳은 x 의 원소 값이 0, False 인 곳은 그대로 출력

        return out

    def backward(self, dout):
        dout[self.mask] = 0
        dx = dout
        return dx

class SoftmaxWithloss:
    def __init__(self):
        self.loss = None
        self.y = None
        self.t = None

    def forward(self, x, t):
        self.t = t
        self.y = softmax(x)
        self.loss = cross_entropy_error(self.y, self.t)

        return self.loss

    def backward(self, dout=1):
        batch_size = self.t.shape[0]
        dx = (self.y - self.t) / batch_size

        return dx

x = np.array([[1, 2]])
w1 = np.array([[1, 3, 5], [2, 4, 6]])
w2 = np.array([[1, 4], [2, 5], [3, 6]])
b1 = np.array([1, 2, 3])
b2 = np.array([1, 2])

# 순전파
affine1 = Affine(w1, b1)
affine2 = Affine(w2, b2)
relu1 = Relu()
relu2 = Relu()

# 은닉 1층
out1 = affine1.forward(x)
relu_out1 = relu1.forward(out1)

# 은닉 2층
out2 = affine2.forward(relu_out1)
relu_out2 = relu2.forward(out2)
print('out : \n', relu_out2)

# softmax
t = np.array([[0, 1]])
softmaxWithloss = SoftmaxWithloss()
loss = softmaxWithloss.forward(relu_out2, t)

# 역전파
dout = softmaxWithloss.backward()
# dout = relu_out2
print('dout : \n', dout)

# 은닉 2층
# relu 통과
relu_dout = relu2.backward(dout)
print('relu_dout : \n', relu_dout)

# affine 통과
dout1, dw2, db2 = affine2.backward(relu_dout)
print('dout1 : \n', dout1)

# 은닉 1층
relu_dout1 = relu1.backward(dout1)
print('relu_dout1 : \n', relu_dout1)
dx, dw1, db1 = affine1.backward(relu_dout1)
print('dx : \n', dx)



 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



  <div class="post-preview">
    <h1>
      <a href="/posts/ML-relu-class-2layer/">파이썬 클래스로 신경망 구현하기(relu,forward,backward)</a>
    </h1>

    <div class="post-content">
      <p>
        





        저번 포스팅 때, 순전파와 역전파 원리를 간단하게 보고, class를 만들어봤습니다. 
이번에는 활성화 함수를 넣어 조금 그럴듯한 신경망을 만들어보도록 하겠습니다. 활성화 함수를 사용하지 않고 열심히 신경망만 깊게 쌓기만 하면 깊게 쌓는 의미도 없을 뿐더라 그냥 단층 신경망이라도 봐도 무방합니다. 그렇기 때문에 꼭 넣어주어야 깊게 쌓는 의미가 있습니다...
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Wed, Dec 25, 2019,  2:00 PM +0800"
  >

  
  

  
    Dec 25, 2019
  

  <i class="unloaded">2019-12-25T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="저번 포스팅 때, 순전파와 역전파 원리를 간단하게 보고, class를 만들어봤습니다. 
이번에는 활성화 함수를 넣어 조금 그럴듯한 신경망을 만들어보도록 하겠습니다. 활성화 함수를 사용하지 않고 열심히 신경망만 깊게 쌓기만 하면 깊게 쌓는 의미도 없을 뿐더라 그냥 단층 신경망이라도 봐도 무방합니다. 그렇기 때문에 꼭 넣어주어야 깊게 쌓는 의미가 있습니다.

Relu Class 만들기.

저번 포스팅에서 만들었던 Affine class는 냅두고 Relu(렐루) 클래스를 한번 만들어 보겠습니다. Relu 함수는 예전 포스팅에서 한번 다루었는데 혹시나 약간 개념이 헷갈리거나 다른 활성화 함수에 대해 알고 싶다면 여기를 눌러 참고해주세요.

Relu의 특징은 0이하면 0을 출력하고 0을 넘으면 그냥 그대로 출력하는 비교적 간단하지만 대단히 효율 좋은 활성화 함수이며 그래프로 출력하지만 아래와 같이 출력할 수 있습니다.



그렇기 때문에 함수 구현이나 클래스는 간단하게 아래와 같이 구현할 수 있습니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
class Relu:
  def __init__(self):
      self.mask = None
      
  def forward(self,x):
      self.mask = (x &lt;= 0)
      out = x.copy()    
      out[self.mask] = 0 
      return out

  def backward(self,dout):
      dout[self.mask] = 0
      dx = dout 
      return dx 


저번에 만든 순전파와 역전파 클래스를 합쳐서 전체 코드를 보면 아래와 같습니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
# 활성화 함수 
class Relu:
  def __init__(self):
      self.mask = None
      
  def forward(self,x):
      self.mask = (x &lt;= 0)
      out = x.copy()    
      out[self.mask] = 0 
      return out

  def backward(self,dout):
      dout[self.mask] = 0
      dx = dout 
      return dx 

# 순전파 역전파
class Affine:
  def __init__(self,w,b):
      self.w = w 
      self.b = b 
      
  def forward(self, x):
      out = np.dot(x,self.w)+ self.b
      return out
      
  def backward(self,x,out):
      dx = np.dot(out,self.w.T)
      dw = np.dot(x.T, out)
      db = np.sum(out, axis = 0) 
      return dx,dw,db


위 클래스를 이용하여 2층짜리 순전파 신경망을 만들어보겠습니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
# input
x = np.array([[1,2]])

# 가중치와 바이어스
w1 = np.array([[1,3,5],[2,4,6]])
w2 = np.array([[1,4],[2,5],[3,6]])
b1 = np.array([1,2,3])
b2 = np.array([1,2])

# 객체화
affine1=Affine(w1,b1)
affine2=Affine(w2,b2)
relu1=Relu()
relu2=Relu()

# 순전파
y1=affine1.forward(x)
out1=relu1.forword(y1)
y2=affine2.forward(y1)
out2=relu2.forword(y2)

print(out2)


순전파를 만들었으니 이번에는 역전파룰 구현해야겠지요? 이미 class안에 함수가 있으니 그대로 불러오면 되겠네요.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
# input
x = np.array([[1,2]])

# 가중치와 바이어스
w2 = np.array([[1,4],[2,5],[3,6]])
b1 = np.array([1,2,3])
b2 = np.array([1,2])

# 객체화
affine1=Affine(w1,b1)
affine2=Affine(w2,b2)
relu1=Relu()
relu2=Relu()

# 순전파
y1=affine1.forward(x)
out1=relu1.forword(y1)
y2=affine2.forward(y1)
out2=relu2.forword(y2)

# 역전파 
dy=relu2.backword(out2)
dx1,dw1,db1=affine2.backward(y1,dy)
dx1=relu1.backword(dx1)
dx,dw,db=affine1.backward(x,dx1)

print('dx:\n',dx)
print('dw:\n',dw)
print('db:\n',db)


잘 출력되는 것을 확인 할 수 있습니다. 다음 포스팅때는 계속 해서 다른 활성화 함수도 구현해보도록 하겠습니다.
 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



  <div class="post-preview">
    <h1>
      <a href="/posts/GO-package-import/">Go언어 문자열 반환하는 함수 만들기</a>
    </h1>

    <div class="post-content">
      <p>
        





        오늘은 GO언어에서 Package, Exported names, 함수에 대해 알아보도록 하겠습니다. 함수는 Python과 비슷해서 어렵지는 않고, 하면서 같이 패키지나 임포트도 잠시 훝어보는 시간을 가져보겠습니다. GO언어가 깔려 있다면 .go 파일을 만들고, 만약에 블로그 예제와 함께 테스트로 돌려보고 싶다면 여기를 눌러 GO놀이터를 이용하여 따라하...
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Wed, Dec 18, 2019,  2:00 PM +0800"
  >

  
  

  
    Dec 18, 2019
  

  <i class="unloaded">2019-12-18T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="오늘은 GO언어에서 Package, Exported names, 함수에 대해 알아보도록 하겠습니다. 함수는 Python과 비슷해서 어렵지는 않고, 하면서 같이 패키지나 임포트도 잠시 훝어보는 시간을 가져보겠습니다. GO언어가 깔려 있다면 .go 파일을 만들고, 만약에 블로그 예제와 함께 테스트로 돌려보고 싶다면 여기를 눌러 GO놀이터를 이용하여 따라하시면 됩니다.

패키지(Package)

GO언어의 모든 프로그램은 패키지로 구성되어 있습니다. 또한 main 패키지에서부터 실행을 시작하며, 패키지 이름은 디렉토리 경로의 마지막 이름을 사용하는 것이 규칙입니다. 예를 들어서 “path/filepath”를 사용한다면 패키지명은 filepath입니다.

1
2
3
4
5
6
7
8
9
packahe main

import "fmt"
import "math"

func main(){
  fmt.Println("Happy", math.pi, "Day")
}
// 출력 결과 : Happy 3.141592653589793 Day


임포트(Imports)

Go언어에서는 여러개의 “Package”를 소괄호로 감싸서 import를 표현합니다. 그래서 아래와 같이 import문장을 여러번 사용 할 수 있습니다.

1
2
3
4
5
6
7
8
9
10
11
12
package main

import ( 
  "fmt" 
  "math" 
)

func main() { 
  fmt.Printf("Now you have %g problems.",
  math.Nextafter(2, 3))
}
// 출력 결과 : Now you have 2.0000000000000004 problems.


익스포트(Exported names)

패키지를 Import 하면 패키지가 외부로 export한 것들(메서드나 변수, 상수등)에 접근 할 수 있습니다. Go언어에서는 첫 문자가 대문자로 시작하면 그 패키지를 사용하는 곳에서 접근 할 수 있는 exported name이 됩니다. 예를 들어 Foo와 FOO는 외부에서 참조할 수 있지만 foo는 참조 할 수 없습니다.

함수(function)

함수에 관해서는 사실 저번 포스팅에서도 잠깐 다룬적이 있습니다. 하지만 오늘은 조금 더 깊게 들어가보도록 하겠습니다. GO의 함수는 다음과 같은 규칙을 같습니다.


  함수는 매개변수(인자)를 가질 수 있습니다.
  두 개 이상의 매개변수가 같은 타입일때, 같은 타입을 취하는 마지막 매개변수에만 타입을 명시하고 나머지는 생락할 수 있습니다.
  하나의 함수가 여러개의 결과를 반환할 수 있습니다.


하나의 함수가 두개의 문자열을 반환하는 함수를 한번 만들어보겠습니다. GO에서는 함수를 만들때, func를 붙이면 함수를 만들 수 있습니다.

1
2
3
4
5
6
7
8
9
10
11
12
13
package main

import "fmt"

func swap(x, y string) (string, string) {
  return y, x
}

func main() {
  a, b := swap("hello", "world")
  fmt.Println(a, b)

}


코드를 보면 함수 swap 라는 함수를 만들었고 문자열 두개를 받아 문자열 두개를 반환하는 함수라는 것을 알 수 있습니다.  swap(x,y string)은 x와 y값을 입력 받는데, 문자열을 받겠다는 뜻이며, 뒤에 있는 (string, strain)은 return값을 문자열로 하겠다는 뜻입니다.

변수

func main()을 살펴보면 :=라는 문자를 볼 수 있는데 함수내에서 짧은 선언을 위해 사용합니다. 월래는 변수를 선언할때, var를 사용합니다. 그래서 a라는 변수에 10이라는 숫자를 넣고 싶다면 아래와 같이 써야하는 것이 맞습니다.

1
var a = 10 


그렇지만 편하게 :=을 사용하면 var과 명시적 타입을 생략 할 수 있습니다. 하지만! 함수 밖에서는 사용할 수 없으니 주의 해주세요. GO에선 변수 선언과 함께 변수 각각을 초기화 할 수있습니다. 초기화 하는 경우 타입을 생략 할 수 있습니다.
 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



  <div class="post-preview">
    <h1>
      <a href="/posts/Deep-feature-lstm-rul/">논문 리뷰 - Predicting remaining useful life of rolling bearings based on deep feature representation and long short-term memory neural network</a>
    </h1>

    <div class="post-content">
      <p>
        





        Paper URL: https://journals.sagepub.com/doi/full/10.1177/1687814018817184

논문 이름이 엄청 길지만 사실 그렇게 심오하지 않는 논문에 대해 요약 리뷰를 해보겠습니다. 이 논문은deep feature extraction에 관련된 논문입니다. 신경망쪽으로 조금 알고 계신분이라면 아마 deep fe...
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Tue, Dec 17, 2019,  2:00 PM +0800"
  >

  
  

  
    Dec 17, 2019
  

  <i class="unloaded">2019-12-17T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="Paper URL: https://journals.sagepub.com/doi/full/10.1177/1687814018817184

논문 이름이 엄청 길지만 사실 그렇게 심오하지 않는 논문에 대해 요약 리뷰를 해보겠습니다. 이 논문은deep feature extraction에 관련된 논문입니다. 신경망쪽으로 조금 알고 계신분이라면 아마 deep feature extraction이 무엇인지는 알고 계실테지만 밑에서 한번 짚고 넘어가겠습니다. 또한 이번 논문은 RUL과 관련이 있기 때문에 RUL이 무엇인지도 알아보겠습니다.

RUL(remaining useful life)

사실 RUL이라는 단어가 사실 정식 단어인지 아닌지는 잘 모르겠습니다. RUL은 어떠한 시스템이나 구성 요소가 교체하기 전에 의도한 목적에 따라 작동 할 수 있을 것으로 추정되는 잔여 수명을 이야기합니다. 즉, 어떠한 부품이 있을때, 이 부품의 남은 수명 같은 개념입니다.

이 논문은 이러한 RUL, 즉 잔존 수명이 얼마나 남았는지를 예측하기 위한 신경망 모델에 대한 논문이며 CNN과 LSTM을 사용하여 모델을 만들었습니다.

Deep feature

deep feature 간단하게 말하면 신경망에서 나오는 feature를 이야기 합니다. 아래의 이미지에서 사람의 사진이 신경망을 거치면서 나오는 저 feature들을 이야기 합니다.



신경망이 학습을 하면서 이미지에서 feature가 추출 되는데 우리는 이것을 deep feature이라고 이야기 합니다. 이러한 deep feature extraction(추출)은 신경망이 학습하면서 좋은 feature를 추출하면 할수록 더 좋은 성능을 뽑게 됩니다. 좋은 feature가 있다는 것은 그 많큼 좋은 성능의 Model이라고도 볼 수 있기 때문입니다.

예를 들어 사과와 바나나를 구별할 때, 사과는 동그랗다 라는 것을 알수 있는 feature와 바나나는 길다 라는 것을 알수 있는 feature를 위주로 뽑아가며 학습을 한다고 가정을 해봅시다. 이 feature들이 뚜렷하고 정확하면 할수록 분류를 잘하기 때문에 좋은 모델이라고도 애기할 수 있습니다.

반대로 이야기 하자면, 좋은 feature를 데이터 Input 값으로 넣는다면 좋은 모델을 뽑을수도 있다는 말로도 바꿀 수 있습니다.

이 점들을 이용해서 요즘은 여러 모델을 섞어서 쓰기도 합니다. 이 논문에서는 CNN과 LSTM을 가지고 모델을 만들었으며 이 논문의 모델의 핵심이 deep feature extraction이기 때문에 deep feature을 짚고 넘어가보았습니다.

DataSet

논문에서 사용된 데이터는 PHM IEEE 2012 Challenge에서 사용된 데이터입니다. PHM 데이터는 진동 데이터입니다. 진동 데이터를 사용한 이유는 수명이 점점 다해가면서 사용 중인 기계의 진동이 점점 강해진다는 점을 파악하여 만들어진 데이터 입니다. 공장에서는 큰 기계를 주로 사용하는데, 고장이나, 수명을 쉽게 파악하기 위해 진동 센서를 붙여 진동의 세기 등을 보고 파악한다고 합니다.



데이터는 위와 같습니다. 베어링 부품의 진동을 수집하였고 수집 상태는 총 3가지로 나눌 수 있으며, 아래와 같습니다.


  First operating conditions: 1800 rpm and 4000 N
  Second operating conditions: 1650 rpm and 4200 N
  Third operating conditions: 1500 rpm and 5000 N


데이터 상세 컬럼은 아래와 같습니다.



시간, 분, 초 등으로 이루어진 데이터라는 것을 알 수 있으며, 데이터 다운로드는 여기에서 보실 수 있고 데이터 상세 설명은 PDF로 같이 있으니 참고 하시길 바랍니다.

Data processing

첫 번째 데이터 전처리 단계에서 원본 데이터를 Hilbert Huang transform(HHT)로 변환합니다. 데이터 변환 후 SVD라고 하여 상관 계수를 구하는 단계를 거치고 데이터를 Input으로 CNN모델에 넣어줍니다.



HHT는 FFT와는 조금 다르니, 위 이미지(흐릿하지만)를 보고 참고 하세요. (a)가 원본 데이터, (b)가 FFT, (c)가 HHT한 데이터 입니다. 더 선명한 이미지는 논문에 있으니 참고하면 될 것 같습니다. 두 번째 전처리 단계는 CNN에서 학습이 끝나면 바로 전 레이어인, full-connected layer 에서 feature를 PCA로 돌려서 4까지 뽑고 LSTM의 Input으로 넣었습니다. 데이터 전처리는 HHT와 SVD와 PCA 이 세가지를 했고 실제로 만들어서 돌려본 결과 HHT하는데 데이터 양이 많아서 그런지는 모르겠지만 시간이 무척이나 걸렸어요.. 시간을 조금 줄이고 싶으신 분은 사실 FFT만 하셔도 무난한 성능을 얻으실 수 있을 것 같습니다.

CNN_LSTM

이 논문에서 만든 모델 Flowchart는 아래와 같습니다.



데이터 전처리 후 CNN Model을 돌리는데, 정확도가 99%가 될때까지 학습을 돌리고, 99%가 되는 순간 마지막 레이어 full-connected layer에서 deep feature extraction을 하게 됩니다. 아마 이 논문에서 가장 중요한 부분이 이 부분 같습니다. 정확도가 높을 때, feature를 뽑는 이유는 제일 좋은 feature를 LSTM Input값으로 넣기 위함이겠죠.

그런데 여기서 바로 feature를 뽑고 LSTM으로 넘기는게 아니라 PCA를 하게 됩니다. 주성분 분석으로 4까지 뽑은 후 LSTM의 Input으로 넣었습니다. CNN은 2layer, Kernel size는 2*2, feature maps 64, 128 입니다. 마지막으로 fun-connected는 25 neuron 입니다. 논문에서는 CNN Train acc 는 100%, Test acc 는 99.53%라고 합니다. LSTM의 파라미터는 자세히는 적혀 있지는 않지만 epoch 40이라고 하네요. 논문의 데이터는 시계열 데이터 이면서 RUL 예측 하기 위한 모델이기 때문에 평가방법은 RMSE를 사용했다고 합니다.

사실 중간에 25개의 통계식과 함께 통계적으로 feature를 나타내어 비교하는 부분이 있으나, 신경망 구현에 있어서 건너뛰어도 무방하여 건너 뛰었습니다.

요약 및 핵심

이 논문에서는 CNN을 좋은 feature를 추출하기 위함으로 사용하였고 LSTM을 이용하여 시계열 데이터를 예측하였습니다. 이렇게 어떠한 모델에서 feature를 추출하는 것을 Deep feature extraction 이라고 부르며, RUL 평가방법으로 RMSE를 사용합니다.

어렵게 볼 논문은 아닌지라, 간단하게 읽고 모델에 대한 영감 받기 좋은 논문인 것 같습니다. 논문보고 구현한 코드는 나중에 올리게 된다면 다시 업데이트 하겠습니다.
 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



  <div class="post-preview">
    <h1>
      <a href="/posts/SQL-Oracle-join-8/">Oracle 조인(join)의 종류(equi join, 1999 ANSI)</a>
    </h1>

    <div class="post-content">
      <p>
        





        오늘부터는 오라클 조인에 대해 알아보도록 하겠습니다. 오라클 조인문법은 어떻게 쓰느냐에 따라 성능 차이가 많이 나기도 하며, 상당히 자주 사용하기 때문에 꼭 알아두어야 합니다. 우선 오늘은 간단하게 오라클 조인의 종류와 간단한 조인 문법에 대해 알아보도록 하겠습니다.

Oracle join 이란 ?

Oracle이 무엇인지는 아마 잘 알고 계실껍니다....
      </p>
    </div>

    <div class="post-meta text-muted d-flex justify-content-between">

      <div>
        <!-- posted date -->
        <i class="far fa-calendar fa-fw"></i>
        <!--
  Date format snippet
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Wed, Dec 11, 2019,  2:00 PM +0800"
  >

  
  

  
    Dec 11, 2019
  

  <i class="unloaded">2019-12-11T14:00:00+08:00</i>

</span>


        <!-- time to read -->
        <!-- <i class="far fa-clock fa-fw"></i> -->
        <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<!-- <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="오늘부터는 오라클 조인에 대해 알아보도록 하겠습니다. 오라클 조인문법은 어떻게 쓰느냐에 따라 성능 차이가 많이 나기도 하며, 상당히 자주 사용하기 때문에 꼭 알아두어야 합니다. 우선 오늘은 간단하게 오라클 조인의 종류와 간단한 조인 문법에 대해 알아보도록 하겠습니다.

Oracle join 이란 ?

Oracle이 무엇인지는 아마 잘 알고 계실껍니다. 오라클은 오라클이라는 회사에서 판매하는 제품 이름입니다. 요즘은 DB제품이 다양하여 꼭 무거운 오라클이 아니더라도 다른 여러 제품을 컨택하여 사용하는 회사들이 많습니다. 여태까지 포스팅 했던 문법들도 전부 Oracle 문법입니다. 그러나 다행이도 DB문법은 다른 회사 제품이더라도 엄청 크게 다르지 않으니, 다른 DB를 사용하고 있어도 큰틀 잡기에는 무리는 없을 것입니다.

Oracle에서 조인(join)이란, 여러 개의 테이블의 컬럼의 결과를 하나의 결과값으로 출력할 떄 사용하는 SQL 문법을 이야기 합니다. 조인 문법은 equi join, non equi join, outer join, self join을 사용하는 오라클 조인 문법과 1999 ANSI 조인 문법이 있습니다.

오라클 조인 문법

오라클 조인 문법에는  equi join, non equi join, outer join, self join이 있다고 위에서 언급했습니다. 생각보다 많아서 어려워 보이지만 어렵지 않습니다. 아래의 표를 참고 한다면 쉽게 이해할 수 있습니다.


  
    
       종류 
      Oracle join 
    
  
  
    
      equi join
      조인하려는 테이블 사이의 연결고리가 = 인 경우의 조인 문법
    
    
      non equi join
      조인하려는 테이블 사이의 연결고리가 /= 인 경우의 조인 문법
    
    
      outer join
      equi 조인으로는 볼 수 없는 결과를 볼 때 사용하는 조인 문법
    
    
      self join
      자기 자신의 테이블과 조인하는 조인 문법
    
  


두 번째 조인인 1999 ANSI 문법 종류는 아래와 같습니다.


  
    
       종류 
    
  
  
    
      on 절을 이용한 join
    
    
      using 절을 이용한  join
    
    
      left/right/full outer join
    
    
      natural join
    
    
      cross join
    
  


이렇게 오라클 조인과 1999 ANSI조인으로 나뉘는 이유는 오라클 조인으로도 조인이 되지 않는 데이터가 있기 때문에 1999 ANSI조인을 사용하여 데이터를 뽑아냅니다.
 words">1 min</span> -->


        <!-- page views -->
        
      </div>

      

    </div> <!-- .post-meta -->

  </div> <!-- .post-review -->



</div> <!-- #post-list -->


  <!--
  The paginator for post list on HomgPage.
-->

<ul class="pagination mt-4 mb-0 pl-lg-2">
  <!-- left arrow -->
  
  <li class="page-item ">
    <a class="page-link btn-box-shadow" href="/page9" aria-label="previous-page">
      <i class="fas fa-angle-left"></i>
    </a>
  </li>

  <!-- page numbers -->
  
  

  

    
    
    
    
    

    

    
      <!-- show number -->
      <li class="page-item ">
        <a class="page-link btn-box-shadow" href="/">1</a>
      </li>
    

  

    
    
    
    
    

    

    
      <!-- hide number -->
      
        <li class="page-item disabled">
          <span class="page-link btn-box-shadow">...</span>
        </li>
        
      
    

  

    
    
    
    
    

    

    
      <!-- hide number -->
      
    

  

    
    
    
    
    

    

    
      <!-- hide number -->
      
    

  

    
    
    
    
    

    

    
      <!-- hide number -->
      
    

  

    
    
    
    
    

    

    
      <!-- hide number -->
      
    

  

    
    
    
    
    

    

    
      <!-- hide number -->
      
    

  

    
    
    
    
    

    

    
      <!-- hide number -->
      
    

  

    
    
    
    
    

    

    
      <!-- show number -->
      <li class="page-item ">
        <a class="page-link btn-box-shadow" href="/page9/">9</a>
      </li>
    

  

    
    
    
    
    

    

    
      <!-- show number -->
      <li class="page-item  active">
        <a class="page-link btn-box-shadow" href="/page10/">10</a>
      </li>
    

  

    
    
    
    
    

    

    
      <!-- show number -->
      <li class="page-item ">
        <a class="page-link btn-box-shadow" href="/page11/">11</a>
      </li>
    

  

    
    
    
    
    

    

    
      <!-- hide number -->
      
        <li class="page-item disabled">
          <span class="page-link btn-box-shadow">...</span>
        </li>
        
      
    

  

    
    
    
    
    

    

    
      <!-- hide number -->
      
    

  

    
    
    
    
    

    

    
      <!-- show number -->
      <li class="page-item ">
        <a class="page-link btn-box-shadow" href="/page14/">14</a>
      </li>
    

  

  <!-- right arrow -->
  
  <li class="page-item ">
    <a class="page-link btn-box-shadow" href="/page11" aria-label="next-page">
      <i class="fas fa-angle-right"></i>
    </a>
  </li>

</ul> <!-- .pagination -->



    
    </div> <!-- #page -->
  </div><!-- .col-12 -->

  <!--
  The Pannel on right side (Desktop views)
-->


</div>
<!-- 
 -->





        <!--
  The Footer
-->

<footer class="d-flex w-100 justify-content-center">
  <div class="d-flex justify-content-between align-items-center">
    <div class="footer-left">
      <p class="mb-0">
        © 2022
        <a href="https://www.instagram.com/ao_ej125">kejdev</a>.
        
        <span data-toggle="tooltip" data-placement="top"
          title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
        
      </p>
    </div>

    <div class="footer-right">
      <p class="mb-0">
        Powered by
        <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
        with
        <a href="https://github.com/cotes2020/jekyll-theme-chirpy"
          target="_blank" rel="noopener">Chirpy</a>
        theme.
      </p>
    </div>

  </div> <!-- div.d-flex -->
</footer>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-xl-11 post-content">
    <div id="search-hints">
      <h4 class="text-muted mb-4">Trending Tags</h4>

      

















      

    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    <!--
  Jekyll Simple Search loader
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="http://localhost:4000{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    <div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div>    <div><i class="fa fa-tag fa-fw"></i>{tags}</div>  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No result founds.</p>'
});
</script>


  </body>

</html>

